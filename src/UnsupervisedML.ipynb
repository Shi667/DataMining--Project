{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import (\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    silhouette_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342d83b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after sampling (k-mean): (735483, 32)\n",
      "Data shape after sampling (dbscan): (147097, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 1. Load your data\n",
    "# -----------------------------\n",
    "data_path_32 = \"../data/preprocessed/preprocessed_reduced_unsupervised_32.csv\"\n",
    "X_data_32 = pd.read_csv(data_path_32)\n",
    "\n",
    "\n",
    "\n",
    "data_path_15 = \"../data/preprocessed/preprocessed_reduced_unsupervised_15.csv\"\n",
    "X_data_15 = pd.read_csv(data_path_15)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Data shape after sampling (k-mean):\", X_data_32.shape)\n",
    "print(\"Data shape after sampling (dbscan):\", X_data_15.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577441ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Grid search for K-Means / MiniBatch K-Means\n",
    "# =========================================================\n",
    "def run_kmeans_grid(\n",
    "    X,\n",
    "    k_values,\n",
    "    output_path:str,\n",
    "    init_methods=(\"k-means++\",),\n",
    "    metrics=(\"ch\", \"dbi\", \"wcss\"),\n",
    "    algorithm=\"kmeans\",  # \"kmeans\" | \"minibatch_kmeans\"\n",
    "    max_iter=300,\n",
    "    n_init=10,\n",
    "    batch_size=1024,     # used only for minibatch_kmeans\n",
    "    random_state=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray of shape (N, d)\n",
    "        Scaled input data\n",
    "    k_values : list[int]\n",
    "        Number of clusters to test\n",
    "    init_methods : tuple[str]\n",
    "        Initialization methods\n",
    "    metrics : tuple[str]\n",
    "        Metrics to compute: {\"ch\", \"dbi\", \"silhouette\", \"wcss\"}\n",
    "    algorithm : str\n",
    "        \"kmeans\" or \"minibatch\"\n",
    "    max_iter : int\n",
    "    n_init : int\n",
    "    batch_size : int\n",
    "        MiniBatchKMeans only\n",
    "    random_state : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pd.DataFrame\n",
    "        Grid search results\n",
    "    \"\"\"\n",
    "\n",
    "    if algorithm not in {\"kmeans\", \"minibatch_kmeans\"}:\n",
    "        raise ValueError(\"algorithm must be 'kmeans' or 'minibatch_kmeans'\")\n",
    "\n",
    "    N = X.shape[0]\n",
    "    results = []\n",
    "\n",
    "    grid = list(product(k_values, init_methods))\n",
    "\n",
    "    for K, init in tqdm(grid, desc=f\"{algorithm} Grid Search\"):\n",
    "\n",
    "        if algorithm == \"kmeans\":\n",
    "            model = KMeans(\n",
    "                n_clusters=K,\n",
    "                init=init,\n",
    "                max_iter=max_iter,\n",
    "                n_init=n_init,\n",
    "                random_state=random_state,\n",
    "                algorithm=\"lloyd\",\n",
    "            )\n",
    "        else:  # MiniBatchKMeans\n",
    "            model = MiniBatchKMeans(\n",
    "                n_clusters=K,\n",
    "                init=init,\n",
    "                max_iter=max_iter,\n",
    "                batch_size=batch_size,\n",
    "                n_init=n_init,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "\n",
    "        labels = model.fit_predict(X)\n",
    "\n",
    "        row = {\n",
    "            \"K\": K,\n",
    "            \"init\": init,\n",
    "            \"algorithm\": algorithm,\n",
    "        }\n",
    "\n",
    "        # -----------------------\n",
    "        # Selected metrics\n",
    "        # -----------------------\n",
    "        if \"ch\" in metrics:\n",
    "            row[\"CH\"] = calinski_harabasz_score(X, labels)\n",
    "\n",
    "        if \"dbi\" in metrics:\n",
    "            row[\"DBI\"] = davies_bouldin_score(X, labels)\n",
    "\n",
    "        if \"silhouette\" in metrics:\n",
    "            # WARNING: O(N^2)\n",
    "            row[\"Silhouette\"] = silhouette_score(X, labels)\n",
    "\n",
    "        if \"wcss\" in metrics:\n",
    "            row[\"WCSS_per_point\"] = model.inertia_ / N\n",
    "\n",
    "        results.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6d347b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch_kmeans Grid Search: 100%|██████████| 48/48 [02:12<00:00,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "results = run_kmeans_grid(\n",
    "    X=X_data_32,\n",
    "    k_values=list(range(3, 51)),  # 3,5,7,...,49\n",
    "    output_path=\"./results/knn_metrics.csv\",\n",
    "    algorithm=\"minibatch_kmeans\",  \n",
    "    batch_size=4096,\n",
    "    metrics=(\"ch\", \"dbi\",\"wcss\"),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7609a6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    K       init         algorithm             CH       DBI  WCSS_per_point\n",
      "0   3  k-means++  minibatch_kmeans  254988.834430  1.721380       16.684688\n",
      "1   5  k-means++  minibatch_kmeans  180414.047959  1.701579       14.263527\n",
      "2   8  k-means++  minibatch_kmeans  147410.138872  1.512309       11.756861\n",
      "3  11  k-means++  minibatch_kmeans  126335.821244  1.505054       10.413611\n",
      "4  12  k-means++  minibatch_kmeans  125704.384579  1.368123        9.811640\n",
      "5  13  k-means++  minibatch_kmeans  124980.671951  1.341546        9.296829\n",
      "6  14  k-means++  minibatch_kmeans  120858.929637  1.329219        9.021307\n",
      "7  16  k-means++  minibatch_kmeans  115956.241494  1.277816        8.403590\n",
      "8  21  k-means++  minibatch_kmeans  117611.923318  1.288624        6.730543\n",
      "9  26  k-means++  minibatch_kmeans  110334.797442  1.211595        5.948190\n"
     ]
    }
   ],
   "source": [
    "def dominates(a, b, metrics, directions):\n",
    "    \"\"\"\n",
    "    Returns True if solution a dominates solution b\n",
    "    \"\"\"\n",
    "    better_or_equal = True\n",
    "    strictly_better = False\n",
    "\n",
    "    for m in metrics:\n",
    "        if directions[m] == \"max\":\n",
    "            if a[m] < b[m]:\n",
    "                better_or_equal = False\n",
    "                break\n",
    "            elif a[m] > b[m]:\n",
    "                strictly_better = True\n",
    "\n",
    "        else:  # minimize\n",
    "            if a[m] > b[m]:\n",
    "                better_or_equal = False\n",
    "                break\n",
    "            elif a[m] < b[m]:\n",
    "                strictly_better = True\n",
    "\n",
    "    return better_or_equal and strictly_better\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "METRIC_DIRECTIONS = {\n",
    "    \"CH\": \"max\",\n",
    "    \"DBI\": \"min\",\n",
    "    \"Silhouette\": \"max\",\n",
    "    \"WCSS_per_point\": \"min\",\n",
    "}\n",
    "\n",
    "def extract_pareto_front(\n",
    "    csv_path,\n",
    "    metrics,\n",
    "    directions=METRIC_DIRECTIONS,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Path to CSV file containing grid search results\n",
    "    metrics : list[str]\n",
    "        Metrics to consider for Pareto dominance\n",
    "    directions : dict\n",
    "        Metric optimization directions (\"min\" or \"max\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pareto_df : pd.DataFrame\n",
    "        Non-dominated solutions\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # --- Safety checks ---\n",
    "    for m in metrics:\n",
    "        if m not in df.columns:\n",
    "            raise ValueError(f\"Metric '{m}' not found in CSV\")\n",
    "        if m not in directions:\n",
    "            raise ValueError(f\"No direction specified for metric '{m}'\")\n",
    "\n",
    "    pareto_mask = [True] * len(df)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if not pareto_mask[i]:\n",
    "            continue\n",
    "\n",
    "        for j in range(len(df)):\n",
    "            if i == j or not pareto_mask[j]:\n",
    "                continue\n",
    "\n",
    "            if dominates(df.iloc[j], df.iloc[i], metrics, directions):\n",
    "                pareto_mask[i] = False\n",
    "                break\n",
    "\n",
    "    pareto_df = df[pareto_mask].reset_index(drop=True)\n",
    "    return pareto_df\n",
    "\n",
    "\n",
    "\n",
    "pareto = extract_pareto_front(\n",
    "    csv_path=\"./results/knn_metrics.csv\",\n",
    "    metrics=[\"CH\", \"DBI\"],\n",
    ")\n",
    "\n",
    "print(pareto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch_kmeans Grid Search:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "results = run_kmeans_grid(\n",
    "    X=X_data_32,\n",
    "    k_values=[3,5,8,11,12,14,16,21,26],  # 3,5,7,...,49\n",
    "    output_path=\"./results/knn_silhouette.csv\",\n",
    "    algorithm=\"minibatch_kmeans\",  \n",
    "    batch_size=4096,\n",
    "    metrics=(\"silhouette\"),\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
