{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4ea82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import (\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "import os\n",
    "import hdbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "342d83b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after sampling (k-mean): (735483, 32)\n",
      "Data shape after sampling (dbscan): (735483, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 1. Load your data\n",
    "# -----------------------------\n",
    "data_path_32 = \"../data/preprocessed/preprocessed_reduced_unsupervised_32.csv\"\n",
    "X_data_32 = pd.read_csv(data_path_32)\n",
    "\n",
    "\n",
    "\n",
    "data_path_10 = \"../data/preprocessed/preprocessed_reduced_unsupervised_10.csv\"\n",
    "X_data_10 = pd.read_csv(data_path_10)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Data shape after sampling (k-mean):\", X_data_32.shape)\n",
    "print(\"Data shape after sampling (dbscan):\", X_data_10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "577441ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(X, labels, total_samples, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    N = len(labels)\n",
    "\n",
    "    indices = []\n",
    "\n",
    "    for k, count in zip(unique_labels, counts):\n",
    "        cluster_idx = np.where(labels == k)[0]\n",
    "        # proportional sampling: fraction of total_samples\n",
    "        n_samples = max(int(total_samples * count / N), 1)\n",
    "\n",
    "        if len(cluster_idx) <= n_samples:\n",
    "            indices.extend(cluster_idx)\n",
    "        else:\n",
    "            indices.extend(rng.choice(cluster_idx, n_samples, replace=False))\n",
    "\n",
    "    # Convert X to NumPy if it's a DataFrame\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.values\n",
    "\n",
    "    return X[indices], labels[indices]\n",
    "\n",
    "\n",
    "\n",
    "def run_kmeans_grid(\n",
    "    X,\n",
    "    k_values,\n",
    "    output_path: str,\n",
    "    init_methods=(\"k-means++\",),\n",
    "    metrics=(\"ch\", \"dbi\", \"wcss\", \"silhouette\"),\n",
    "    algorithm=\"kmeans\",  # \"kmeans\" | \"minibatch_kmeans\"\n",
    "    max_iter=300,\n",
    "    n_init=10,\n",
    "    batch_size=1024,  # only for minibatch_kmeans\n",
    "    random_state=42,\n",
    "    silhouette_sample_size=50_000,\n",
    "    silhouette_n_repeats=5,  # number of times to repeat silhouette evaluation\n",
    "):\n",
    "    if algorithm not in {\"kmeans\", \"minibatch_kmeans\"}:\n",
    "        raise ValueError(\"algorithm must be 'kmeans' or 'minibatch_kmeans'\")\n",
    "\n",
    "    N = X.shape[0]\n",
    "    results = []\n",
    "\n",
    "    grid = list(product(k_values, init_methods))\n",
    "\n",
    "    for K, init in tqdm(grid, desc=f\"{algorithm} Grid Search\"):\n",
    "\n",
    "        # Fit KMeans / MiniBatchKMeans\n",
    "        if algorithm == \"kmeans\":\n",
    "            model = KMeans(\n",
    "                n_clusters=K,\n",
    "                init=init,\n",
    "                max_iter=max_iter,\n",
    "                n_init=n_init,\n",
    "                random_state=random_state,\n",
    "                algorithm=\"lloyd\",\n",
    "            )\n",
    "        else:\n",
    "            model = MiniBatchKMeans(\n",
    "                n_clusters=K,\n",
    "                init=init,\n",
    "                max_iter=max_iter,\n",
    "                batch_size=batch_size,\n",
    "                n_init=n_init,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "\n",
    "        labels = model.fit_predict(X)\n",
    "\n",
    "        row = {\n",
    "            \"K\": K,\n",
    "            \"init\": init,\n",
    "            \"algorithm\": algorithm,\n",
    "        }\n",
    "\n",
    "        # -----------------------\n",
    "        # Metrics\n",
    "        # -----------------------\n",
    "        if \"ch\" in metrics:\n",
    "            row[\"CH\"] = calinski_harabasz_score(X, labels)\n",
    "\n",
    "        if \"dbi\" in metrics:\n",
    "            row[\"DBI\"] = davies_bouldin_score(X, labels)\n",
    "\n",
    "        if \"silhouette\" in metrics:\n",
    "            silhouette_scores = []\n",
    "            for i in range(silhouette_n_repeats):\n",
    "                Xs, ls = stratified_sample(\n",
    "                    X,\n",
    "                    labels,\n",
    "                    total_samples=silhouette_sample_size,\n",
    "                    random_state=random_state + i,  # different seed each time\n",
    "                )\n",
    "                silhouette_scores.append(silhouette_score(Xs, ls))\n",
    "\n",
    "            row[\"Silhouette\"] = np.mean(silhouette_scores)  # average over repeats\n",
    "            row[\"Silhouette_std\"] = np.std(silhouette_scores)  # optional: track variability\n",
    "\n",
    "        if \"wcss\" in metrics:\n",
    "            row[\"WCSS_per_point\"] = model.inertia_ / N\n",
    "\n",
    "        results.append(row)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6d347b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch_kmeans Grid Search: 100%|██████████| 48/48 [02:12<00:00,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "results = run_kmeans_grid(\n",
    "    X=X_data_32,\n",
    "    k_values=list(range(3, 51)),  # 3,5,7,...,49\n",
    "    output_path=\"./results/knn_metrics.csv\",\n",
    "    algorithm=\"minibatch_kmeans\",  \n",
    "    batch_size=4096,\n",
    "    metrics=(\"ch\", \"dbi\",\"wcss\"),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7609a6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    K       init         algorithm             CH       DBI  WCSS_per_point\n",
      "0   3  k-means++  minibatch_kmeans  254988.834430  1.721380       16.684688\n",
      "1   5  k-means++  minibatch_kmeans  180414.047959  1.701579       14.263527\n",
      "2   8  k-means++  minibatch_kmeans  147410.138872  1.512309       11.756861\n",
      "3  11  k-means++  minibatch_kmeans  126335.821244  1.505054       10.413611\n",
      "4  12  k-means++  minibatch_kmeans  125704.384579  1.368123        9.811640\n",
      "5  13  k-means++  minibatch_kmeans  124980.671951  1.341546        9.296829\n",
      "6  14  k-means++  minibatch_kmeans  120858.929637  1.329219        9.021307\n",
      "7  16  k-means++  minibatch_kmeans  115956.241494  1.277816        8.403590\n",
      "8  21  k-means++  minibatch_kmeans  117611.923318  1.288624        6.730543\n",
      "9  26  k-means++  minibatch_kmeans  110334.797442  1.211595        5.948190\n"
     ]
    }
   ],
   "source": [
    "def dominates(a, b, metrics, directions):\n",
    "    \"\"\"\n",
    "    Returns True if solution a dominates solution b\n",
    "    \"\"\"\n",
    "    better_or_equal = True\n",
    "    strictly_better = False\n",
    "\n",
    "    for m in metrics:\n",
    "        if directions[m] == \"max\":\n",
    "            if a[m] < b[m]:\n",
    "                better_or_equal = False\n",
    "                break\n",
    "            elif a[m] > b[m]:\n",
    "                strictly_better = True\n",
    "\n",
    "        else:  # minimize\n",
    "            if a[m] > b[m]:\n",
    "                better_or_equal = False\n",
    "                break\n",
    "            elif a[m] < b[m]:\n",
    "                strictly_better = True\n",
    "\n",
    "    return better_or_equal and strictly_better\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "METRIC_DIRECTIONS = {\n",
    "    \"CH\": \"max\",\n",
    "    \"DBI\": \"min\",\n",
    "    \"Silhouette\": \"max\",\n",
    "    \"WCSS_per_point\": \"min\",\n",
    "}\n",
    "\n",
    "def extract_pareto_front(\n",
    "    csv_path,\n",
    "    metrics,\n",
    "    directions=METRIC_DIRECTIONS,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Path to CSV file containing grid search results\n",
    "    metrics : list[str]\n",
    "        Metrics to consider for Pareto dominance\n",
    "    directions : dict\n",
    "        Metric optimization directions (\"min\" or \"max\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pareto_df : pd.DataFrame\n",
    "        Non-dominated solutions\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # --- Safety checks ---\n",
    "    for m in metrics:\n",
    "        if m not in df.columns:\n",
    "            raise ValueError(f\"Metric '{m}' not found in CSV\")\n",
    "        if m not in directions:\n",
    "            raise ValueError(f\"No direction specified for metric '{m}'\")\n",
    "\n",
    "    pareto_mask = [True] * len(df)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if not pareto_mask[i]:\n",
    "            continue\n",
    "\n",
    "        for j in range(len(df)):\n",
    "            if i == j or not pareto_mask[j]:\n",
    "                continue\n",
    "\n",
    "            if dominates(df.iloc[j], df.iloc[i], metrics, directions):\n",
    "                pareto_mask[i] = False\n",
    "                break\n",
    "\n",
    "    pareto_df = df[pareto_mask].reset_index(drop=True)\n",
    "    return pareto_df\n",
    "\n",
    "\n",
    "\n",
    "pareto = extract_pareto_front(\n",
    "    csv_path=\"./results/knn_metrics.csv\",\n",
    "    metrics=[\"CH\", \"DBI\"],\n",
    ")\n",
    "\n",
    "print(pareto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cd6890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch_kmeans Grid Search: 100%|██████████| 9/9 [55:06<00:00, 367.38s/it]\n"
     ]
    }
   ],
   "source": [
    "results = run_kmeans_grid(\n",
    "    X=X_data_32,\n",
    "    k_values=[3,5,8,11,12,14,16,21,26],  # 3,5,7,...,49\n",
    "    n_init=10,\n",
    "    output_path=\"./results/knn_silhouette.csv\",\n",
    "    algorithm=\"minibatch_kmeans\",  \n",
    "    batch_size=4096,\n",
    "    metrics=(\"silhouette\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_hdbscan_grid(\n",
    "    X,\n",
    "    min_cluster_sizes,\n",
    "    min_samples_values,\n",
    "    output_path: str,\n",
    "    metrics=(\"ch\", \"dbi\", \"silhouette\"),\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"eom\",\n",
    "    silhouette_sample_size=50_000,\n",
    "    silhouette_n_repeats=5,\n",
    "    random_state=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    HDBSCAN grid search with:\n",
    "    - number of clusters\n",
    "    - number & percentage of outliers\n",
    "    - internal clustering metrics\n",
    "    - incremental CSV saving (safe for long runs)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create CSV with header if it doesn't exist\n",
    "    if not os.path.exists(output_path):\n",
    "        pd.DataFrame().to_csv(output_path, index=False)\n",
    "\n",
    "    grid = list(product(min_cluster_sizes, min_samples_values))\n",
    "\n",
    "    for min_cs, min_s in tqdm(grid, desc=\"HDBSCAN Grid Search\"):\n",
    "\n",
    "        # -----------------------\n",
    "        # Fit HDBSCAN\n",
    "        # -----------------------\n",
    "        clusterer = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=min_cs,\n",
    "            min_samples=min_s,\n",
    "            metric=metric,\n",
    "            cluster_selection_method=cluster_selection_method,\n",
    "        )\n",
    "\n",
    "        labels = clusterer.fit_predict(X)\n",
    "\n",
    "        N = len(labels)\n",
    "        n_noise = np.sum(labels == -1)\n",
    "        noise_ratio = n_noise / N\n",
    "\n",
    "        unique_clusters = set(labels)\n",
    "        n_clusters = len(unique_clusters) - (1 if -1 in unique_clusters else 0)\n",
    "\n",
    "        row = {\n",
    "            \"algorithm\": \"hdbscan\",\n",
    "            \"min_cluster_size\": min_cs,\n",
    "            \"min_samples\": min_s,\n",
    "            \"n_clusters\": n_clusters,\n",
    "            \"n_noise\": n_noise,\n",
    "            \"noise_ratio\": noise_ratio,\n",
    "        }\n",
    "\n",
    "        # Remove noise for metric computation\n",
    "        mask = labels != -1\n",
    "        X_clean = X[mask]\n",
    "        labels_clean = labels[mask]\n",
    "\n",
    "        # -----------------------\n",
    "        # Metrics\n",
    "        # -----------------------\n",
    "        if len(np.unique(labels_clean)) >= 2:\n",
    "\n",
    "            if \"ch\" in metrics:\n",
    "                row[\"CH\"] = calinski_harabasz_score(X_clean, labels_clean)\n",
    "\n",
    "            if \"dbi\" in metrics:\n",
    "                row[\"DBI\"] = davies_bouldin_score(X_clean, labels_clean)\n",
    "\n",
    "            if \"silhouette\" in metrics:\n",
    "                sil_scores = []\n",
    "\n",
    "                for i in range(silhouette_n_repeats):\n",
    "                    rng = np.random.RandomState(random_state + i)\n",
    "\n",
    "                    if X_clean.shape[0] > silhouette_sample_size:\n",
    "                        idx = rng.choice(\n",
    "                            X_clean.shape[0],\n",
    "                            silhouette_sample_size,\n",
    "                            replace=False,\n",
    "                        )\n",
    "                        sil_scores.append(\n",
    "                            silhouette_score(X_clean[idx], labels_clean[idx])\n",
    "                        )\n",
    "                    else:\n",
    "                        sil_scores.append(\n",
    "                            silhouette_score(X_clean, labels_clean)\n",
    "                        )\n",
    "\n",
    "                row[\"Silhouette\"] = np.mean(sil_scores)\n",
    "                row[\"Silhouette_std\"] = np.std(sil_scores)\n",
    "\n",
    "\n",
    "        else:\n",
    "            # Degenerate solution: all noise or one cluster\n",
    "            row[\"CH\"] = np.nan\n",
    "            row[\"DBI\"] = np.nan\n",
    "            row[\"Silhouette\"] = np.nan\n",
    "            row[\"Silhouette_std\"] = np.nan\n",
    "\n",
    "        # -----------------------\n",
    "        # Save immediately\n",
    "        # -----------------------\n",
    "        df_row = pd.DataFrame([row])\n",
    "        df_row.to_csv(\n",
    "            output_path,\n",
    "            mode=\"a\",\n",
    "            header=not os.path.getsize(output_path),\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "        # Print after each evaluation\n",
    "        print(row)\n",
    "\n",
    "    return pd.read_csv(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d2609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:   5%|▌         | 1/20 [09:51<3:07:26, 591.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 50, 'min_samples': 5, 'n_clusters': 4896, 'n_noise': np.int64(132861), 'noise_ratio': np.float64(0.18064455602644794), 'CH': 9171.463955278918, 'DBI': 0.8613381514160154, 'WCSS': ae_feature_0    1904.976222\n",
      "ae_feature_1    2187.019630\n",
      "ae_feature_2    2610.673438\n",
      "ae_feature_3    1770.657166\n",
      "ae_feature_4    1794.338724\n",
      "ae_feature_5    2028.925024\n",
      "ae_feature_6    1534.773417\n",
      "ae_feature_7    1365.848959\n",
      "ae_feature_8    3307.210763\n",
      "ae_feature_9    1770.328046\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  10%|█         | 2/20 [19:08<2:51:24, 571.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 50, 'min_samples': 10, 'n_clusters': 4705, 'n_noise': np.int64(141521), 'noise_ratio': np.float64(0.19241913137353275), 'CH': 9613.115812421172, 'DBI': 0.8402605206507678, 'WCSS': ae_feature_0    1637.425615\n",
      "ae_feature_1    2211.965408\n",
      "ae_feature_2    2542.972394\n",
      "ae_feature_3    1769.443822\n",
      "ae_feature_4    1698.391460\n",
      "ae_feature_5    2122.254359\n",
      "ae_feature_6    1459.864554\n",
      "ae_feature_7    1353.819022\n",
      "ae_feature_8    3033.734207\n",
      "ae_feature_9    1665.027780\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  15%|█▌        | 3/20 [28:13<2:38:23, 559.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 50, 'min_samples': 20, 'n_clusters': 4348, 'n_noise': np.int64(164588), 'noise_ratio': np.float64(0.2237821948297921), 'CH': 10901.939547762211, 'DBI': 0.7858744066065787, 'WCSS': ae_feature_0    1311.279903\n",
      "ae_feature_1    2042.126547\n",
      "ae_feature_2    2304.419526\n",
      "ae_feature_3    1639.257572\n",
      "ae_feature_4    1416.645972\n",
      "ae_feature_5    1808.275445\n",
      "ae_feature_6    1285.162150\n",
      "ae_feature_7    1195.780749\n",
      "ae_feature_8    2810.135014\n",
      "ae_feature_9    1408.050353\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  20%|██        | 4/20 [33:25<2:03:03, 461.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 50, 'min_samples': 50, 'n_clusters': 2817, 'n_noise': np.int64(205932), 'noise_ratio': np.float64(0.27999559473162533), 'CH': 11404.679120484165, 'DBI': 0.7131264394375787, 'WCSS': ae_feature_0    1446.083768\n",
      "ae_feature_1    2822.704816\n",
      "ae_feature_2    3140.337292\n",
      "ae_feature_3    2446.752774\n",
      "ae_feature_4    1672.456282\n",
      "ae_feature_5    2257.644770\n",
      "ae_feature_6    1454.121199\n",
      "ae_feature_7    1539.360471\n",
      "ae_feature_8    3413.806977\n",
      "ae_feature_9    1684.746211\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  25%|██▌       | 5/20 [37:49<1:37:34, 390.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 100, 'min_samples': 5, 'n_clusters': 1817, 'n_noise': np.int64(107569), 'noise_ratio': np.float64(0.14625626968944216), 'CH': 11220.06161127598, 'DBI': 1.0447686624851438, 'WCSS': ae_feature_0    3656.902318\n",
      "ae_feature_1    5955.956548\n",
      "ae_feature_2    7084.562907\n",
      "ae_feature_3    4630.062525\n",
      "ae_feature_4    4010.296643\n",
      "ae_feature_5    4969.147300\n",
      "ae_feature_6    3324.838880\n",
      "ae_feature_7    2888.743519\n",
      "ae_feature_8    7083.710121\n",
      "ae_feature_9    3946.680020\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  30%|███       | 6/20 [42:21<1:21:42, 350.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 100, 'min_samples': 10, 'n_clusters': 1603, 'n_noise': np.int64(101255), 'noise_ratio': np.float64(0.13767143496178702), 'CH': 10337.616303649264, 'DBI': 1.0471441211718502, 'WCSS': ae_feature_0    3875.780241\n",
      "ae_feature_1    9114.425265\n",
      "ae_feature_2    9505.378473\n",
      "ae_feature_3    6578.004698\n",
      "ae_feature_4    4442.908176\n",
      "ae_feature_5    6080.397838\n",
      "ae_feature_6    3596.598363\n",
      "ae_feature_7    3266.115467\n",
      "ae_feature_8    7961.603214\n",
      "ae_feature_9    4487.454255\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  35%|███▌      | 7/20 [46:59<1:10:44, 326.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 100, 'min_samples': 20, 'n_clusters': 1482, 'n_noise': np.int64(110475), 'noise_ratio': np.float64(0.1502074147193069), 'CH': 10828.90538858892, 'DBI': 1.0131244363516427, 'WCSS': ae_feature_0    3586.702142\n",
      "ae_feature_1    9298.645199\n",
      "ae_feature_2    9812.105168\n",
      "ae_feature_3    6712.461031\n",
      "ae_feature_4    4212.477135\n",
      "ae_feature_5    6026.491122\n",
      "ae_feature_6    3407.928910\n",
      "ae_feature_7    3183.378224\n",
      "ae_feature_8    8172.297760\n",
      "ae_feature_9    4307.494234\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  40%|████      | 8/20 [51:55<1:03:23, 316.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 100, 'min_samples': 50, 'n_clusters': 1117, 'n_noise': np.int64(133634), 'noise_ratio': np.float64(0.1816955660429949), 'CH': 12354.581972751314, 'DBI': 0.9555195940977038, 'WCSS': ae_feature_0     3635.086677\n",
      "ae_feature_1     9760.653718\n",
      "ae_feature_2    11454.281453\n",
      "ae_feature_3     7224.402862\n",
      "ae_feature_4     4524.496049\n",
      "ae_feature_5     6734.028462\n",
      "ae_feature_6     3473.879529\n",
      "ae_feature_7     3416.516728\n",
      "ae_feature_8     8322.031815\n",
      "ae_feature_9     4600.600309\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  45%|████▌     | 9/20 [56:14<54:47, 298.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 200, 'min_samples': 5, 'n_clusters': 743, 'n_noise': np.int64(84125), 'noise_ratio': np.float64(0.11438061790687208), 'CH': 14732.085831867687, 'DBI': 1.246674383919357, 'WCSS': ae_feature_0     6457.569773\n",
      "ae_feature_1    14017.030413\n",
      "ae_feature_2    15325.860308\n",
      "ae_feature_3     9399.449346\n",
      "ae_feature_4     6716.730094\n",
      "ae_feature_5     9425.904977\n",
      "ae_feature_6     5410.555842\n",
      "ae_feature_7     4947.423230\n",
      "ae_feature_8    12931.692165\n",
      "ae_feature_9     7138.556696\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  50%|█████     | 10/20 [1:00:40<48:04, 288.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 200, 'min_samples': 10, 'n_clusters': 668, 'n_noise': np.int64(77475), 'noise_ratio': np.float64(0.1053389405329559), 'CH': 15382.296571852172, 'DBI': 1.2270765132152626, 'WCSS': ae_feature_0     6575.143712\n",
      "ae_feature_1    15601.337216\n",
      "ae_feature_2    17395.932697\n",
      "ae_feature_3    10649.586866\n",
      "ae_feature_4     6950.999766\n",
      "ae_feature_5    10127.724371\n",
      "ae_feature_6     5844.294255\n",
      "ae_feature_7     5000.959634\n",
      "ae_feature_8    13047.569238\n",
      "ae_feature_9     7239.238511\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  55%|█████▌    | 11/20 [1:05:10<42:26, 283.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 200, 'min_samples': 20, 'n_clusters': 661, 'n_noise': np.int64(88982), 'noise_ratio': np.float64(0.1209844415166632), 'CH': 15974.81674241059, 'DBI': 1.205005259036342, 'WCSS': ae_feature_0     5706.535737\n",
      "ae_feature_1    15153.357658\n",
      "ae_feature_2    16373.356998\n",
      "ae_feature_3    10236.324939\n",
      "ae_feature_4     6423.476755\n",
      "ae_feature_5     9849.889824\n",
      "ae_feature_6     5230.802069\n",
      "ae_feature_7     4699.499722\n",
      "ae_feature_8    11821.524223\n",
      "ae_feature_9     6825.573433\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  60%|██████    | 12/20 [1:10:03<38:08, 286.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 200, 'min_samples': 50, 'n_clusters': 550, 'n_noise': np.int64(97745), 'noise_ratio': np.float64(0.13289906088923878), 'CH': 15464.683692850305, 'DBI': 1.1185523937460142, 'WCSS': ae_feature_0     6404.609136\n",
      "ae_feature_1    18469.376503\n",
      "ae_feature_2    18267.874350\n",
      "ae_feature_3    10908.612957\n",
      "ae_feature_4     7918.678864\n",
      "ae_feature_5    12836.302768\n",
      "ae_feature_6     5513.250836\n",
      "ae_feature_7     6993.228049\n",
      "ae_feature_8    13555.702426\n",
      "ae_feature_9     8743.009087\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  65%|██████▌   | 13/20 [1:21:02<46:31, 398.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 500, 'min_samples': 5, 'n_clusters': 333, 'n_noise': np.int64(72849), 'noise_ratio': np.float64(0.09904919624246923), 'CH': 19520.458469499044, 'DBI': 1.477029953709076, 'WCSS': ae_feature_0    13038.453805\n",
      "ae_feature_1    23653.843157\n",
      "ae_feature_2    23237.422425\n",
      "ae_feature_3    13774.557384\n",
      "ae_feature_4    11251.490018\n",
      "ae_feature_5    16367.776090\n",
      "ae_feature_6     8334.965611\n",
      "ae_feature_7     9363.046942\n",
      "ae_feature_8    20017.138628\n",
      "ae_feature_9    13147.369468\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  70%|███████   | 14/20 [1:25:10<35:20, 353.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 500, 'min_samples': 10, 'n_clusters': 304, 'n_noise': np.int64(71311), 'noise_ratio': np.float64(0.09695805341523869), 'CH': 20098.32679103336, 'DBI': 1.4504874849050242, 'WCSS': ae_feature_0    12838.252534\n",
      "ae_feature_1    26325.195751\n",
      "ae_feature_2    24895.832748\n",
      "ae_feature_3    14498.565355\n",
      "ae_feature_4    11662.955407\n",
      "ae_feature_5    17160.633329\n",
      "ae_feature_6     8326.301381\n",
      "ae_feature_7     9622.504609\n",
      "ae_feature_8    21647.030706\n",
      "ae_feature_9    13737.684811\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  75%|███████▌  | 15/20 [1:29:26<26:59, 323.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 500, 'min_samples': 20, 'n_clusters': 299, 'n_noise': np.int64(78395), 'noise_ratio': np.float64(0.10658981920724205), 'CH': 21257.88444829589, 'DBI': 1.4295759292641526, 'WCSS': ae_feature_0    11083.316018\n",
      "ae_feature_1    25161.507960\n",
      "ae_feature_2    23876.961337\n",
      "ae_feature_3    14627.064010\n",
      "ae_feature_4    11179.492839\n",
      "ae_feature_5    16695.648385\n",
      "ae_feature_6     7787.950011\n",
      "ae_feature_7     9122.799122\n",
      "ae_feature_8    19485.112736\n",
      "ae_feature_9    12658.696097\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  80%|████████  | 16/20 [1:34:04<20:40, 310.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 500, 'min_samples': 50, 'n_clusters': 295, 'n_noise': np.int64(93779), 'noise_ratio': np.float64(0.12750668608247914), 'CH': 24703.715102483402, 'DBI': 1.3340416980474894, 'WCSS': ae_feature_0     8497.584769\n",
      "ae_feature_1    20896.331823\n",
      "ae_feature_2    21618.992030\n",
      "ae_feature_3    13235.736254\n",
      "ae_feature_4     9497.693498\n",
      "ae_feature_5    14035.099793\n",
      "ae_feature_6     6375.687808\n",
      "ae_feature_7     7454.417119\n",
      "ae_feature_8    16047.876930\n",
      "ae_feature_9     9439.066311\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  85%|████████▌ | 17/20 [1:38:05<14:28, 289.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 1000, 'min_samples': 5, 'n_clusters': 191, 'n_noise': np.int64(80860), 'noise_ratio': np.float64(0.10994135826388918), 'CH': 25034.36931778628, 'DBI': 1.6094857989036444, 'WCSS': ae_feature_0    19098.750516\n",
      "ae_feature_1    30928.553817\n",
      "ae_feature_2    26569.637610\n",
      "ae_feature_3    16020.833030\n",
      "ae_feature_4    15681.987726\n",
      "ae_feature_5    20884.901957\n",
      "ae_feature_6    11353.114853\n",
      "ae_feature_7    12532.831467\n",
      "ae_feature_8    23630.781867\n",
      "ae_feature_9    18474.050619\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  90%|█████████ | 18/20 [1:42:13<09:13, 276.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 1000, 'min_samples': 10, 'n_clusters': 186, 'n_noise': np.int64(87669), 'noise_ratio': np.float64(0.1191992201043396), 'CH': 27565.36467344073, 'DBI': 1.6213186785981404, 'WCSS': ae_feature_0    16371.552735\n",
      "ae_feature_1    27906.379734\n",
      "ae_feature_2    26935.896712\n",
      "ae_feature_3    16226.320915\n",
      "ae_feature_4    14295.305269\n",
      "ae_feature_5    18406.904630\n",
      "ae_feature_6    10432.204091\n",
      "ae_feature_7    10395.578268\n",
      "ae_feature_8    22010.647658\n",
      "ae_feature_9    15433.984887\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search:  95%|█████████▌| 19/20 [1:46:25<04:29, 269.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 1000, 'min_samples': 20, 'n_clusters': 185, 'n_noise': np.int64(95088), 'noise_ratio': np.float64(0.12928646889187106), 'CH': 27930.08263966517, 'DBI': 1.5998466732280687, 'WCSS': ae_feature_0    15918.056955\n",
      "ae_feature_1    27357.436802\n",
      "ae_feature_2    26526.519074\n",
      "ae_feature_3    15814.317662\n",
      "ae_feature_4    13712.543237\n",
      "ae_feature_5    18114.901448\n",
      "ae_feature_6     9444.075308\n",
      "ae_feature_7    10147.271740\n",
      "ae_feature_8    21119.397391\n",
      "ae_feature_9    14702.237520\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Grid Search: 100%|██████████| 20/20 [1:50:58<00:00, 332.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 1000, 'min_samples': 50, 'n_clusters': 174, 'n_noise': np.int64(107191), 'noise_ratio': np.float64(0.1457423217123985), 'CH': 29329.604730543622, 'DBI': 1.4589200360601353, 'WCSS': ae_feature_0    14375.044213\n",
      "ae_feature_1    27391.152312\n",
      "ae_feature_2    25517.505758\n",
      "ae_feature_3    15262.104495\n",
      "ae_feature_4    13019.377237\n",
      "ae_feature_5    17882.186885\n",
      "ae_feature_6     7959.508951\n",
      "ae_feature_7    10431.774058\n",
      "ae_feature_8    21287.833577\n",
      "ae_feature_9    13197.291996\n",
      "dtype: float64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = run_hdbscan_grid(\n",
    "    X=X_data_10,\n",
    "    min_cluster_sizes=[50, 100, 200, 500, 1000],\n",
    "    min_samples_values=[5, 10, 20, 50],\n",
    "    output_path=\"./results/hdbscan_results.csv\",\n",
    "    metrics=(\"ch\", \"dbi\", \"wcss\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66e8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_by_noise_ratio(\n",
    "    input_csv_path: str,\n",
    "    output_csv_path: str,\n",
    "    min_noise_ratio: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Keep only rows where noise_ratio >= min_noise_ratio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_csv_path : str\n",
    "        Path to input CSV (must contain 'noise_ratio' column)\n",
    "    output_csv_path : str\n",
    "        Path where filtered CSV will be saved\n",
    "    min_noise_ratio : float\n",
    "        Minimum noise_ratio to keep (e.g. 0.15)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "\n",
    "    if \"noise_ratio\" not in df.columns:\n",
    "        raise ValueError(\"Column 'noise_ratio' not found in CSV\")\n",
    "\n",
    "    df_filtered = df[df[\"noise_ratio\"] <= min_noise_ratio]\n",
    "\n",
    "    df_filtered.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    print(f\"Saved {len(df_filtered)} / {len(df)} rows to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9bd9d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 18 / 20 rows to ./results/hdbscan_results_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "filter_by_noise_ratio(\"./results/hdbscan_results.csv\",\"./results/hdbscan_results_filtered.csv\",min_noise_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb473d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  algorithm  min_cluster_sizes  min_samples  n_clusters  n_noise  noise_ratio  \\\n",
      "0   hdbscan                 50           10        4705   141521     0.192419   \n",
      "1   hdbscan                100           50        1117   133634     0.181696   \n",
      "2   hdbscan                200           20         661    88982     0.120984   \n",
      "3   hdbscan                200           50         550    97745     0.132899   \n",
      "4   hdbscan                500           50         295    93779     0.127507   \n",
      "5   hdbscan               1000           50         174   107191     0.145742   \n",
      "\n",
      "             CH       DBI  \n",
      "0   9613.115812  0.840261  \n",
      "1  12354.581973  0.955520  \n",
      "2  15974.816742  1.205005  \n",
      "3  15464.683693  1.118552  \n",
      "4  24703.715102  1.334042  \n",
      "5  29329.604731  1.458920  \n"
     ]
    }
   ],
   "source": [
    "pareto = extract_pareto_front(\n",
    "    csv_path=\"./results/hdbscan_results_filtered.csv\",\n",
    "    metrics=[\"CH\", \"DBI\"],\n",
    ")\n",
    "\n",
    "print(pareto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "074b58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hdbscan\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "\n",
    "\n",
    "def _get_non_existing_path(path):\n",
    "    \"\"\"Add suffix (_1, _2, ...) if file already exists.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return path\n",
    "\n",
    "    base, ext = os.path.splitext(path)\n",
    "    i = 1\n",
    "    new_path = f\"{base}_{i}{ext}\"\n",
    "    while os.path.exists(new_path):\n",
    "        i += 1\n",
    "        new_path = f\"{base}_{i}{ext}\"\n",
    "    return new_path\n",
    "\n",
    "\n",
    "def run_hdbscan_combinations(\n",
    "    X,\n",
    "    param_combinations,\n",
    "    output_path: str,\n",
    "    metrics=(\"ch\", \"dbi\", \"silhouette\"),\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"eom\",\n",
    "    silhouette_sample_size=50_000,\n",
    "    silhouette_n_repeats=5,\n",
    "    random_state=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run HDBSCAN on explicit parameter combinations and save results to CSV.\n",
    "    \"\"\"\n",
    "\n",
    "    output_path = _get_non_existing_path(output_path)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for params in tqdm(param_combinations, desc=\"HDBSCAN Runs\"):\n",
    "\n",
    "        min_cs = params[\"min_cluster_size\"]\n",
    "        min_s = params[\"min_samples\"]\n",
    "\n",
    "        # -----------------------\n",
    "        # Fit HDBSCAN\n",
    "        # -----------------------\n",
    "        clusterer = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=min_cs,\n",
    "            min_samples=min_s,\n",
    "            metric=metric,\n",
    "            cluster_selection_method=cluster_selection_method,\n",
    "        )\n",
    "\n",
    "        labels = clusterer.fit_predict(X)\n",
    "\n",
    "        N = len(labels)\n",
    "        n_noise = np.sum(labels == -1)\n",
    "        noise_ratio = n_noise / N\n",
    "\n",
    "        unique_clusters = set(labels)\n",
    "        n_clusters = len(unique_clusters) - (1 if -1 in unique_clusters else 0)\n",
    "\n",
    "        row = {\n",
    "            \"algorithm\": \"hdbscan\",\n",
    "            \"min_cluster_size\": min_cs,\n",
    "            \"min_samples\": min_s,\n",
    "            \"n_clusters\": n_clusters,\n",
    "            \"n_noise\": n_noise,\n",
    "            \"noise_ratio\": noise_ratio,\n",
    "        }\n",
    "\n",
    "        # -----------------------\n",
    "        # Remove noise\n",
    "        # -----------------------\n",
    "        mask = labels != -1\n",
    "\n",
    "        # Ensure NumPy arrays (IMPORTANT)\n",
    "        X_clean = X[mask]\n",
    "        if isinstance(X_clean, pd.DataFrame):\n",
    "            X_clean = X_clean.to_numpy()\n",
    "\n",
    "        labels_clean = labels[mask]\n",
    "\n",
    "\n",
    "        # -----------------------\n",
    "        # Metrics\n",
    "        # -----------------------\n",
    "        if len(np.unique(labels_clean)) >= 2:\n",
    "\n",
    "            if \"ch\" in metrics:\n",
    "                row[\"CH\"] = calinski_harabasz_score(X_clean, labels_clean)\n",
    "\n",
    "            if \"dbi\" in metrics:\n",
    "                row[\"DBI\"] = davies_bouldin_score(X_clean, labels_clean)\n",
    "\n",
    "            if \"silhouette\" in metrics:\n",
    "                sil_scores = []\n",
    "\n",
    "                for i in range(silhouette_n_repeats):\n",
    "                    rng = np.random.RandomState(random_state + i)\n",
    "\n",
    "                    if X_clean.shape[0] > silhouette_sample_size:\n",
    "                        idx = rng.choice(\n",
    "                            X_clean.shape[0],\n",
    "                            silhouette_sample_size,\n",
    "                            replace=False,\n",
    "                        )\n",
    "                        sil_scores.append(\n",
    "                            silhouette_score(X_clean[idx], labels_clean[idx])\n",
    "                        )\n",
    "                    else:\n",
    "                        sil_scores.append(\n",
    "                            silhouette_score(X_clean, labels_clean)\n",
    "                        )\n",
    "\n",
    "                row[\"Silhouette\"] = np.mean(sil_scores)\n",
    "                row[\"Silhouette_std\"] = np.std(sil_scores)\n",
    "\n",
    "        else:\n",
    "            row[\"CH\"] = np.nan\n",
    "            row[\"DBI\"] = np.nan\n",
    "            row[\"Silhouette\"] = np.nan\n",
    "            row[\"Silhouette_std\"] = np.nan\n",
    "\n",
    "        # -----------------------\n",
    "        # Save incrementally\n",
    "        # -----------------------\n",
    "        df_row = pd.DataFrame([row])\n",
    "        df_row.to_csv(\n",
    "            output_path,\n",
    "            mode=\"a\",\n",
    "            header=not os.path.exists(output_path) or os.path.getsize(output_path) == 0,\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "        print(row)\n",
    "\n",
    "        all_rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(all_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a48cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Runs:  17%|█▋        | 1/6 [12:31<1:02:36, 751.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 50, 'min_samples': 10, 'n_clusters': 4705, 'n_noise': np.int64(141521), 'noise_ratio': np.float64(0.19241913137353275), 'CH': 9613.115812421172, 'DBI': 0.8402605206507678, 'Silhouette': np.float64(0.415047631999162), 'Silhouette_std': np.float64(0.0012099766964917239)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Runs:  33%|███▎      | 2/6 [21:20<41:23, 620.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 100, 'min_samples': 50, 'n_clusters': 1117, 'n_noise': np.int64(133634), 'noise_ratio': np.float64(0.1816955660429949), 'CH': 12354.581972751314, 'DBI': 0.9555195940977038, 'Silhouette': np.float64(0.24981478331024148), 'Silhouette_std': np.float64(0.001807645142020548)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Runs:  50%|█████     | 3/6 [29:19<27:47, 555.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 200, 'min_samples': 20, 'n_clusters': 661, 'n_noise': np.int64(88982), 'noise_ratio': np.float64(0.1209844415166632), 'CH': 15974.81674241059, 'DBI': 1.205005259036342, 'Silhouette': np.float64(0.21911689986108668), 'Silhouette_std': np.float64(0.001626174528131428)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "HDBSCAN Runs:  67%|██████▋   | 4/6 [37:17<17:30, 525.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 200, 'min_samples': 50, 'n_clusters': 550, 'n_noise': np.int64(97745), 'noise_ratio': np.float64(0.13289906088923878), 'CH': 15464.683692850305, 'DBI': 1.1185523937460142, 'Silhouette': np.float64(0.22099316894987764), 'Silhouette_std': np.float64(0.0016330261896091833)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Runs:  83%|████████▎ | 5/6 [44:55<08:20, 500.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 500, 'min_samples': 50, 'n_clusters': 295, 'n_noise': np.int64(93779), 'noise_ratio': np.float64(0.12750668608247914), 'CH': 24703.715102483402, 'DBI': 1.3340416980474894, 'Silhouette': np.float64(0.22021246746883166), 'Silhouette_std': np.float64(0.0010693207788540038)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HDBSCAN Runs: 100%|██████████| 6/6 [52:35<00:00, 526.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'hdbscan', 'min_cluster_size': 1000, 'min_samples': 50, 'n_clusters': 174, 'n_noise': np.int64(107191), 'noise_ratio': np.float64(0.1457423217123985), 'CH': 29329.604730543622, 'DBI': 1.4589200360601353, 'Silhouette': np.float64(0.20762483780073993), 'Silhouette_std': np.float64(0.001571614176482901)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_combinations = [\n",
    "    {\"min_cluster_size\": 50, \"min_samples\": 10},\n",
    "    {\"min_cluster_size\": 100, \"min_samples\": 50},\n",
    "    {\"min_cluster_size\": 200, \"min_samples\": 20},\n",
    "    {\"min_cluster_size\": 200, \"min_samples\": 50},\n",
    "    {\"min_cluster_size\": 500, \"min_samples\": 50},\n",
    "    {\"min_cluster_size\": 1000, \"min_samples\": 50},\n",
    "    \n",
    "]\n",
    "\n",
    "df = run_hdbscan_combinations(\n",
    "    X=X_data_10,\n",
    "    param_combinations=param_combinations,\n",
    "    output_path=\"./results/hdbscan_selected_runs.csv\",\n",
    "    metrics=(\"ch\", \"dbi\",\"silhouette\"),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
