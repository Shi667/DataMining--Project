{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859f5f99",
   "metadata": {},
   "source": [
    "# üß™ Work Overview\n",
    "\n",
    "In this work, we will:\n",
    "\n",
    "üßº Clean and preprocess multiple datasets (elevation, soil, climate, etc.)\n",
    "\n",
    "üîó Merge them into a single unified dataset\n",
    "\n",
    "üîç Run tests to check whether feature reduction is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c71268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.dataMerging.combineDatasets import extract_features_elevation , extract_features_landcover , extract_features_monthly_clim , extract_features_soil , organize_monthly_climat_files\n",
    "from scripts.dataMerging.mergeDataSources import progressive_merge\n",
    "from scripts.dataMerging.generateGrid import generate_grid_in_shape\n",
    "from scripts.dataPreprocessing.dataCleaning import process_fire_data , treat_sensor_errors_soil , impute_with_geo_zones \n",
    "from scripts.dataPreprocessing.scalingEncoding import scalingEncodingDataset\n",
    "from scripts.statistics.firePerSeason import calculate_seasonal_fire_percentage\n",
    "from scripts.dataPreprocessing.featureReduction import analyze_correlation_variance , reduce_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92275cd4",
   "metadata": {},
   "source": [
    "### üó∫Ô∏è Reference Grid\n",
    "\n",
    "üìê Create a reference grid with consistent latitude and longitude\n",
    "\n",
    "üîó Ensures all datasets align and can be merged correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e89d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading shapefile...\n",
      "üó∫Ô∏è Bounding box: [-8.67386818 18.96023083 11.98736715 37.55986   ]\n",
      "üìè Grid: 414 √ó 372 = 154,008 total potential points\n",
      "üîç Filtering points inside region...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Generate grid (only once)\n",
    "grid_df = generate_grid_in_shape(\n",
    "    \"../data/shapefiles/combined/alg_tun.shp\",\n",
    "    resolution=0.05, # 1 KM resolution\n",
    "    output_csv=\"../data/features/grid_points.csv\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d8cf15",
   "metadata": {},
   "source": [
    "## üî• Extract Nearest Points (cKDTree)\n",
    "\n",
    "üå≥ Use cKDTree to find the nearest grid point for each fire record\n",
    "\n",
    "üìç Matches fire locations to the reference grid efficiently\n",
    "\n",
    "‚ö° Fast nearest-neighbor search for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb16ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved (91102, 3) grid points with binary fire data (1/0) to ../data/preprocessed/fire_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the paths and parameters\n",
    "GRID_FILE = \"../data/features/grid_points.csv\"\n",
    "FIRE_FILE = \"../data/fire_dataset/viirs-jpss1_2024_alg_Tun.csv\"\n",
    "TARGET_FIRE_TYPE = 2 \n",
    "\n",
    "process_fire_data(\n",
    "    grid_path=GRID_FILE,\n",
    "    fire_path=FIRE_FILE,\n",
    "    target_type=TARGET_FIRE_TYPE,\n",
    "    output_file=\"../data/preprocessed/fire_preprocessed.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d434e06",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Climat Dataset\n",
    "\n",
    "‚ùÑÔ∏è Extract seasonal data (winter, spring, summer, autumn)\n",
    "\n",
    "üõ†Ô∏è Preprocess by fixing missing values using the median Apply regional resolution \n",
    "\n",
    "üìè Scale features using a Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afbf1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Month 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 16902.22it/s]\n",
      "Month 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17152.60it/s]\n",
      "Month 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17599.95it/s]\n",
      "Month 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17683.50it/s]\n",
      "Month 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17917.60it/s]\n",
      "Month 06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17457.01it/s]\n",
      "Month 07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17267.99it/s]\n",
      "Month 08: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17682.10it/s]\n",
      "Month 09: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17741.55it/s]\n",
      "Month 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17570.98it/s]\n",
      "Month 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17742.28it/s]\n",
      "Month 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 16119.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished sampling all monthly rasters.\n",
      "üíæ Saved seasonal climatology to ../data/features/grid_tmax.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Month 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17164.27it/s]\n",
      "Month 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17421.64it/s]\n",
      "Month 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17535.59it/s]\n",
      "Month 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17689.60it/s]\n",
      "Month 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17271.66it/s]\n",
      "Month 06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17327.70it/s]\n",
      "Month 07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17552.22it/s]\n",
      "Month 08: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17687.10it/s]\n",
      "Month 09: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17418.78it/s]\n",
      "Month 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17533.51it/s]\n",
      "Month 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17699.85it/s]\n",
      "Month 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 16917.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished sampling all monthly rasters.\n",
      "üíæ Saved seasonal climatology to ../data/features/grid_tmin.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Month 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 16942.11it/s]\n",
      "Month 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17350.03it/s]\n",
      "Month 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17683.45it/s]\n",
      "Month 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17577.25it/s]\n",
      "Month 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17537.23it/s]\n",
      "Month 06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17601.81it/s]\n",
      "Month 07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17400.62it/s]\n",
      "Month 08: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17255.79it/s]\n",
      "Month 09: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17506.95it/s]\n",
      "Month 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17288.24it/s]\n",
      "Month 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17433.51it/s]\n",
      "Month 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:05<00:00, 17483.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished sampling all monthly rasters.\n",
      "üíæ Saved seasonal climatology to ../data/features/grid_tprec.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Organize the files\n",
    "monthly_tmax_data = organize_monthly_climat_files(\n",
    "    \"../data/climate_dataset/5min/max/*.tif\"\n",
    ")\n",
    "monthly_tmin_data = organize_monthly_climat_files(\n",
    "    \"../data/climate_dataset/5min/min/*.tif\"\n",
    ")\n",
    "monthly_tprec_data = organize_monthly_climat_files(\n",
    "    \"../data/climate_dataset/5min/prec/*.tif\"\n",
    ")\n",
    "\n",
    "\n",
    "extract_features_monthly_clim(\n",
    "    point_csv=\"../data/features/grid_points.csv\",\n",
    "    raster_dict=monthly_tmax_data,\n",
    "    output_path=\"../data/features/grid_tmax.csv\",\n",
    "    col_name=\"tmax\",\n",
    ")\n",
    "\n",
    "\n",
    "extract_features_monthly_clim(\n",
    "    point_csv=\"../data/features/grid_points.csv\",\n",
    "    raster_dict=monthly_tmin_data,\n",
    "    output_path=\"../data/features/grid_tmin.csv\",\n",
    "    col_name=\"tmin\",\n",
    ")\n",
    "\n",
    "\n",
    "extract_features_monthly_clim(\n",
    "    point_csv=\"../data/features/grid_points.csv\",\n",
    "    raster_dict=monthly_tprec_data,\n",
    "    output_path=\"../data/features/grid_tprec.csv\",\n",
    "    col_name=\"prec\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd545be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>18609</td>\n",
       "      <td>20.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spring</td>\n",
       "      <td>23093</td>\n",
       "      <td>25.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer</td>\n",
       "      <td>24667</td>\n",
       "      <td>27.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autumn/Fall</td>\n",
       "      <td>23881</td>\n",
       "      <td>26.46%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Season  Count Percentage\n",
       "3       Winter  18609     20.62%\n",
       "2       Spring  23093     25.59%\n",
       "0       Summer  24667     27.33%\n",
       "1  Autumn/Fall  23881     26.46%"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_seasonal_fire_percentage('../data/fire_dataset/viirs-jpss1_2024_alg_Tun.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df16c36",
   "metadata": {},
   "source": [
    "### üìä Seasonal Fire Distribution\n",
    "üî• As we can see, fires occur almost equally across all seasons\n",
    "\n",
    "‚ö†Ô∏è Therefore, dropping any season‚Äôs climat data is not advisable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7878f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (percent) per column :\n",
      "winter_tmax    0.356743\n",
      "spring_tmax    0.356743\n",
      "summer_tmax    0.356743\n",
      "autumn_tmax    0.356743\n",
      "dtype: float64\n",
      "\n",
      "=== Imputing column: winter_tmax ===\n",
      "winter_tmax: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: spring_tmax ===\n",
      "spring_tmax: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: summer_tmax ===\n",
      "summer_tmax: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: autumn_tmax ===\n",
      "autumn_tmax: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_tmax_clean.csv\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/tmax_preprocessed.csv\n",
      "Missing values (percent) per column :\n",
      "winter_tmin    0.356743\n",
      "spring_tmin    0.356743\n",
      "summer_tmin    0.356743\n",
      "autumn_tmin    0.356743\n",
      "dtype: float64\n",
      "\n",
      "=== Imputing column: winter_tmin ===\n",
      "winter_tmin: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: spring_tmin ===\n",
      "spring_tmin: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: summer_tmin ===\n",
      "summer_tmin: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: autumn_tmin ===\n",
      "autumn_tmin: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_tmin_clean.csv\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/tmin_preprocessed.csv\n",
      "Missing values (percent) per column :\n",
      "winter_prec    0.356743\n",
      "spring_prec    0.356743\n",
      "summer_prec    0.356743\n",
      "autumn_prec    0.356743\n",
      "dtype: float64\n",
      "\n",
      "=== Imputing column: winter_prec ===\n",
      "winter_prec: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: spring_prec ===\n",
      "spring_prec: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: summer_prec ===\n",
      "summer_prec: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: autumn_prec ===\n",
      "autumn_prec: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_prec_clean.csv\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/prec_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "impute_with_geo_zones(\"../data/features/grid_tmax.csv\", base_res=0.05 , min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_tmax_clean.csv\")\n",
    "scalingEncodingDataset(\"../data/features_cleaned/grid_tmax_clean.csv\",\"../data/preprocessed/tmax_preprocessed.csv\")\n",
    "\n",
    "impute_with_geo_zones(\"../data/features/grid_tmin.csv\", base_res=0.05, min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_tmin_clean.csv\")\n",
    "scalingEncodingDataset(\"../data/features_cleaned/grid_tmin_clean.csv\",\"../data/preprocessed/tmin_preprocessed.csv\")\n",
    "\n",
    "\n",
    "impute_with_geo_zones(\"../data/features/grid_tprec.csv\", base_res=0.05 , min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_prec_clean.csv\")\n",
    "scalingEncodingDataset(\"../data/features_cleaned/grid_prec_clean.csv\",\"../data/preprocessed/prec_preprocessed.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5402e",
   "metadata": {},
   "source": [
    "## üå≥ Landcover Dataset\n",
    "\n",
    "üå± Extract landcover values from the reference grid\n",
    "\n",
    "üõ†Ô∏è Preprocess by handling missing values using the median Applying regional resolution\n",
    "\n",
    "üìè Scale features using a Robust Scaler\n",
    "\n",
    "‚úÖ We only kept the gridcode feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ededd",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features_landcover(\n",
    "    csv_path=\"../data/features/grid_points.csv\",\n",
    "    shapefile_path=\"../data/land_dataset/combined/alg_tun_landcvr.shp\",\n",
    "    lat_col=\"latitude\",\n",
    "    lon_col=\"longitude\",\n",
    "    keep_cols=[\"GRIDCODE\"],  # can be [\"GRIDCODE\", \"CLASS\", \"AREA\", ...]\n",
    "    output_path=\"../data/features/grid_landcover.csv\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c3b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (percent) per column :\n",
      "GRIDCODE    0.051591\n",
      "dtype: float64\n",
      "\n",
      "=== Imputing column: GRIDCODE ===\n",
      "GRIDCODE: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_landcover_clean.csv\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/landcover_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "impute_with_geo_zones(\"../data/features/grid_landcover.csv\", base_res=0.05, min_points=10 ,max_res=0.2, output_path=\"../data/features_cleaned/grid_landcover_clean.csv\")\n",
    "scalingEncodingDataset(\"../data/features_cleaned/grid_landcover_clean.csv\",\"../data/preprocessed/landcover_preprocessed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2792ed",
   "metadata": {},
   "source": [
    "## üå± Soil Dataset\n",
    "\n",
    "üß± Extract soil features from the reference grid\n",
    "\n",
    "üõ†Ô∏è Preprocess missing and invalid data\n",
    "\n",
    "Rows with negative values (likely sensor errors) are treated as missing Apply regional resolution\n",
    "\n",
    "üé® Feature selection & encoding\n",
    "\n",
    "TEXTURE_SOTER and TEXTURE_USDA have the same meaning\n",
    "\n",
    "Keep only TEXTURE_USDA (more detailed)\n",
    "\n",
    "Apply One-Hot Encoding to TEXTURE_USDA\n",
    "\n",
    "üìè Scale features using a Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features_soil(\n",
    "    csv_path=\"../data/features/grid_points.csv\",\n",
    "    raster_path=\"../data/soil_dataset/original/HWSD2_RASTER/HWSD2.bil\",\n",
    "    soil_attributes_csv=\"../data/soil_dataset/simplified/D1_soil_features_alg_tun.csv\",\n",
    "    output_soil_ids=\"../data/features/fire_soil_ids.csv\",\n",
    "    output_soil_feature=\"../data/features/grid_soil.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/features/grid_soil.csv\")\n",
    "if \"TEXTURE_SOTER\" in df.columns:\n",
    "        df.drop(columns=[\"TEXTURE_SOTER\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Cleaning complete!\n",
      "  Deleted rows : 15998\n",
      "  Fixed rows   : 21237\n"
     ]
    }
   ],
   "source": [
    "treat_sensor_errors_soil(\"../data/features/grid_soil.csv\",output_path=\"../data/features/grid_soil_treated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (percent) per column :\n",
      "COARSE          11.772825\n",
      "SAND            11.772825\n",
      "SILT            11.772825\n",
      "CLAY            11.772825\n",
      "TEXTURE_USDA    11.772825\n",
      "BULK            11.772825\n",
      "REF_BULK        11.772825\n",
      "ORG_CARBON      11.772825\n",
      "PH_WATER        11.772825\n",
      "TOTAL_N         11.772825\n",
      "CN_RATIO        11.772825\n",
      "CEC_SOIL        11.772825\n",
      "CEC_CLAY        11.772825\n",
      "CEC_EFF         11.772825\n",
      "TEB             11.772825\n",
      "BSAT            11.772825\n",
      "ALUM_SAT        11.772825\n",
      "ESP             11.772825\n",
      "TCARBON_EQ      11.772825\n",
      "GYPSUM          11.772825\n",
      "ELEC_COND       11.772825\n",
      "dtype: float64\n",
      "\n",
      "=== Imputing column: COARSE ===\n",
      "COARSE: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: SAND ===\n",
      "SAND: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: SILT ===\n",
      "SILT: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: CLAY ===\n",
      "CLAY: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: TEXTURE_USDA ===\n",
      "TEXTURE_USDA: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: BULK ===\n",
      "BULK: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: REF_BULK ===\n",
      "REF_BULK: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: ORG_CARBON ===\n",
      "ORG_CARBON: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: PH_WATER ===\n",
      "PH_WATER: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: TOTAL_N ===\n",
      "TOTAL_N: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: CN_RATIO ===\n",
      "CN_RATIO: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: CEC_SOIL ===\n",
      "CEC_SOIL: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: CEC_CLAY ===\n",
      "CEC_CLAY: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: CEC_EFF ===\n",
      "CEC_EFF: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: TEB ===\n",
      "TEB: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: BSAT ===\n",
      "BSAT: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: ALUM_SAT ===\n",
      "ALUM_SAT: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: ESP ===\n",
      "ESP: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: TCARBON_EQ ===\n",
      "TCARBON_EQ: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: GYPSUM ===\n",
      "GYPSUM: imputation done using geo-zones.\n",
      "\n",
      "=== Imputing column: ELEC_COND ===\n",
      "ELEC_COND: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_soil_clean.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "CATEGORICAL_COLS_SOIL = [\"TEXTURE_USDA\"]  # categorical columns\n",
    "NUMERIC_COLS_SOIL = [\n",
    "    \"COARSE\", \"SAND\", \"SILT\", \"CLAY\", \"BULK\", \"REF_BULK\", \"ORG_CARBON\", \"PH_WATER\",\n",
    "    \"TOTAL_N\", \"CN_RATIO\", \"CEC_SOIL\", \"CEC_CLAY\", \"CEC_EFF\", \"TEB\", \"BSAT\",\n",
    "    \"ALUM_SAT\", \"ESP\", \"TCARBON_EQ\", \"GYPSUM\", \"ELEC_COND\"\n",
    "]  # numeric columns\n",
    "\n",
    "# Usage\n",
    "soil_cleaned = impute_with_geo_zones(\"../data/features/grid_soil_treated.csv\",num_cols=NUMERIC_COLS_SOIL , cat_cols=CATEGORICAL_COLS_SOIL,  base_res=0.05, min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_soil_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c46c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXTURE_USDA classes found: [np.int64(3), np.int64(5), np.int64(7), np.int64(9), np.int64(10), np.int64(11), np.int64(12)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/soil_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "scalingEncodingDataset(\"../data/features_cleaned/grid_soil_clean.csv\",\"../data/preprocessed/soil_preprocessed.csv\",categorical_col=[\"TEXTURE_USDA\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573fbbf",
   "metadata": {},
   "source": [
    "## üèîÔ∏è Elevation Dataset\n",
    "\n",
    "üóª Extract elevation values from the reference grid\n",
    "\n",
    "üõ†Ô∏è Preprocess by handling missing values using the median\n",
    "\n",
    "üåç Apply regional resolution if needed\n",
    "\n",
    "üìè Scale features using a Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b10cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 91102 points from ../data/features/grid_points.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting elevation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:06<00:00, 14398.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved extracted elevation to ../data/features/grid_elevation.csv\n"
     ]
    }
   ],
   "source": [
    "fires_with_elevation = extract_features_elevation(\n",
    "    raster_path=\"../data/elevation_dataset/simplified/elevation_clipped.tif\",\n",
    "    fire_csv_path=\"../data/features/grid_points.csv\",\n",
    "    output_csv=\"../data/features/grid_elevation.csv\",\n",
    "    value_name=\"elevation\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038afea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (percent) per column :\n",
      "Series([], dtype: float64)\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_elevation_clean.csv\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/elevation_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "impute_with_geo_zones(\"../data/features/grid_elevation.csv\", base_res=0.05, min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_elevation_clean.csv\")\n",
    "scalingEncodingDataset(\"../data/features_cleaned/grid_elevation_clean.csv\",\"../data/preprocessed/elevation_preprocessed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce3326",
   "metadata": {},
   "source": [
    "## üìä Merging Preprocessed Datasets\n",
    "Merging all preprocessed datasets on the common key fields of longitude and latitude to obtain one final, unified dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bdab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading first CSV: ../data/preprocessed/tmax_preprocessed.csv\n",
      "üîÅ Merging file 2/7: ../data/preprocessed/tmin_preprocessed.csv\n",
      "‚úÖ Intermediate merged size: (91102, 10)\n",
      "üîÅ Merging file 3/7: ../data/preprocessed/prec_preprocessed.csv\n",
      "‚úÖ Intermediate merged size: (91102, 14)\n",
      "üîÅ Merging file 4/7: ../data/preprocessed/landcover_preprocessed.csv\n",
      "‚úÖ Intermediate merged size: (91102, 15)\n",
      "üîÅ Merging file 5/7: ../data/preprocessed/elevation_preprocessed.csv\n",
      "‚úÖ Intermediate merged size: (91102, 16)\n",
      "üîÅ Merging file 6/7: ../data/preprocessed/soil_preprocessed.csv\n",
      "‚úÖ Intermediate merged size: (180407, 43)\n",
      "üîÅ Merging file 7/7: ../data/preprocessed/fire_preprocessed.csv\n",
      "‚úÖ Intermediate merged size: (180407, 44)\n",
      "‚úÖ All files merged successfully.\n"
     ]
    }
   ],
   "source": [
    "csv_list= [\"../data/preprocessed/tmax_preprocessed.csv\", \"../data/preprocessed/tmin_preprocessed.csv\",\"../data/preprocessed/prec_preprocessed.csv\",  \"../data/preprocessed/landcover_preprocessed.csv\" , \"../data/preprocessed/elevation_preprocessed.csv\" , \"../data/preprocessed/soil_preprocessed.csv\",\"../data/preprocessed/fire_preprocessed.csv\"]\n",
    "temp_df = progressive_merge(\n",
    "    csv_list,\n",
    "    on=[\"latitude\", \"longitude\"],\n",
    "    how=\"inner\",\n",
    "    output_path=\"../data/Merged/merged.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa6e4f2",
   "metadata": {},
   "source": [
    "## üìâ Feature Reduction Analysis\n",
    "\n",
    "üìä Visualize feature variance\n",
    "\n",
    "Sort features by descending variance to identify those that contribute most\n",
    "\n",
    "üîé Very low-variance features carry little information and can be removed\n",
    "\n",
    "üîó Check highly correlated features\n",
    "\n",
    "Detect pairs with high correlation (above a chosen threshold)\n",
    "\n",
    "üîÅ Highly correlated features bring redundant information, so one of them can be safely dropped\n",
    "\n",
    "üå≤ Random Forest Feature Selection\n",
    "\n",
    "Apply a Random Forest model to rank feature importance\n",
    "\n",
    "Keep only the top 30 features for a cleaner and more efficient dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32a23661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlated pairs:\n",
      "('spring_tmax', 'winter_tmax', np.float64(0.9703100202516131))\n",
      "('spring_tmax', 'spring_tmin', np.float64(0.9677018264099003))\n",
      "('summer_tmax', 'summer_tmin', np.float64(0.9536581957776394))\n",
      "('autumn_tmax', 'spring_tmax', np.float64(0.9626003029397542))\n",
      "('autumn_tmax', 'autumn_tmin', np.float64(0.959645622916126))\n",
      "('spring_tmin', 'winter_tmax', np.float64(0.9569806753519634))\n",
      "('CLAY', 'REF_BULK', np.float64(0.9508329083694732))\n",
      "('CEC_EFF', 'TEB', np.float64(0.9678396950125807))\n",
      "('ELEC_COND', 'ESP', np.float64(0.9725718830636039))\n",
      "\n",
      "Feature variances:\n",
      "TEX_7             0.000233\n",
      "TEX_10            0.005156\n",
      "TEX_3             0.006378\n",
      "TEX_12            0.013310\n",
      "TEX_5             0.048565\n",
      "TEX_9             0.227349\n",
      "TEX_11            0.244526\n",
      "SAND              0.325793\n",
      "PH_WATER          0.327004\n",
      "SILT              0.350165\n",
      "CEC_CLAY          0.352965\n",
      "BULK              0.446971\n",
      "winter_tmin       0.477026\n",
      "summer_tmax       0.571274\n",
      "CN_RATIO          0.593874\n",
      "BSAT              0.625279\n",
      "COARSE            0.630275\n",
      "elevation         0.718927\n",
      "ALUM_SAT          0.757094\n",
      "winter_tmax       0.758416\n",
      "summer_prec       0.815856\n",
      "summer_tmin       0.826959\n",
      "spring_tmin       0.837833\n",
      "TCARBON_EQ        0.858480\n",
      "spring_tmax       0.906190\n",
      "REF_BULK          0.989960\n",
      "autumn_tmin       1.001215\n",
      "autumn_tmax       1.003510\n",
      "CEC_SOIL          1.134988\n",
      "TEB               1.158792\n",
      "CLAY              1.229174\n",
      "TOTAL_N           1.278946\n",
      "autumn_prec       2.224055\n",
      "CEC_EFF           2.468524\n",
      "spring_prec       4.166602\n",
      "GYPSUM            4.868445\n",
      "ORG_CARBON        9.726218\n",
      "ELEC_COND        12.945271\n",
      "winter_prec      28.469989\n",
      "ESP             153.730106\n",
      "GRIDCODE       2334.946373\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "res = analyze_correlation_variance(\"../data/Merged/merged.csv\" ,target_col=\"fire\", corr_threshold=0.95,)\n",
    "\n",
    "print(\"Correlated pairs:\")\n",
    "for p in res[\"correlated_pairs\"]:\n",
    "    print(p)\n",
    "\n",
    "print(\"\\nFeature variances:\")\n",
    "print(res[\"variances\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c49c791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['elevation', 'spring_prec', 'winter_prec', 'autumn_prec', 'GRIDCODE', 'summer_prec', 'winter_tmin', 'ORG_CARBON', 'CEC_CLAY', 'GYPSUM', 'SAND', 'SILT', 'TOTAL_N', 'PH_WATER', 'BULK', 'BSAT', 'TCARBON_EQ', 'COARSE', 'CEC_SOIL', 'CN_RATIO', 'TEX_9', 'TEX_11', 'TEX_5', 'ALUM_SAT', 'TEX_12']\n"
     ]
    }
   ],
   "source": [
    "reduced = reduce_features(\n",
    "    \"../data/Merged/merged.csv\",\n",
    "    output_path=\"../data/Merged/reduced_data.csv\",\n",
    "    var_threshold=0.01,\n",
    "    corr_threshold=0.95,\n",
    "    importance_method=\"RF\",\n",
    "    top_k=30\n",
    ")\n",
    "\n",
    "print(\"Selected features:\", reduced[\"selected_features\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
=======
  "cells": [
    {
      "cell_type": "markdown",
      "id": "859f5f99",
      "metadata": {},
      "source": [
        "# üß™ Work Overview\n",
        "\n",
        "In this work, we will:\n",
        "\n",
        "üßº Clean and preprocess multiple datasets (elevation, soil, climate, etc.)\n",
        "\n",
        "üîó Merge them into a single unified dataset\n",
        "\n",
        "üîç Run tests to check whether feature reduction is possible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "43c71268",
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts.dataMerging.combineDatasets import extract_features_elevation , extract_features_landcover , extract_features_monthly_clim , extract_features_soil , organize_monthly_climat_files\n",
        "from scripts.dataMerging.mergeDataSources import progressive_merge\n",
        "from scripts.dataMerging.generateGrid import generate_grid_in_shape\n",
        "from scripts.dataPreprocessing.dataCleaning import process_fire_data , treat_sensor_errors_soil , impute_with_geo_zones \n",
        "from scripts.dataPreprocessing.scalingEncoding import scalingEncodingDataset\n",
        "from scripts.statistics.firePerSeason import calculate_seasonal_fire_percentage\n",
        "from scripts.dataPreprocessing.featureReduction import analyze_correlation_variance , reduce_features\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92275cd4",
      "metadata": {},
      "source": [
        "### üó∫Ô∏è Reference Grid\n",
        "\n",
        "üìê Create a reference grid with consistent latitude and longitude\n",
        "\n",
        "üîó Ensures all datasets align and can be merged correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3e89d5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Loading shapefile...\n",
            "üó∫Ô∏è Bounding box: [-8.67386818 18.96023083 11.98736715 37.55986   ]\n",
            "üìè Grid: 414 √ó 372 = 154,008 total potential points\n",
            "üîç Filtering points inside region...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Generate grid (only once)\n",
        "grid_df = generate_grid_in_shape(\n",
        "    \"../data/shapefiles/combined/alg_tun.shp\",\n",
        "    resolution=0.03, # 3 KM resolution\n",
        "    output_csv=\"../data/features/grid_points.csv\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99d8cf15",
      "metadata": {},
      "source": [
        "## üî• Extract Nearest Points (cKDTree)\n",
        "\n",
        "üå≥ Use cKDTree to find the nearest grid point for each fire record\n",
        "\n",
        "üìç Matches fire locations to the reference grid efficiently\n",
        "\n",
        "‚ö° Fast nearest-neighbor search for large datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb16ea0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved (91102, 3) grid points with binary fire data (1/0) to ../data/preprocessed/fire_preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the paths and parameters\n",
        "GRID_FILE = \"../data/features/grid_points.csv\"\n",
        "FIRE_FILE = \"../data/fire_dataset/viirs-jpss1_2024_alg_Tun.csv\"\n",
        "TARGET_FIRE_TYPE = 2 \n",
        "\n",
        "process_fire_data(\n",
        "    grid_path=GRID_FILE,\n",
        "    fire_path=FIRE_FILE,\n",
        "    target_type=TARGET_FIRE_TYPE,\n",
        "    output_file=\"../data/preprocessed/fire_preprocessed.csv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d434e06",
      "metadata": {},
      "source": [
        "## ‚òÅÔ∏è Climat Dataset\n",
        "\n",
        "‚ùÑÔ∏è Extract seasonal data (winter, spring, summer, autumn)\n",
        "\n",
        "üõ†Ô∏è Preprocess by fixing missing values using the median Apply regional resolution \n",
        "\n",
        "üìè Scale features using a Robust Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6afbf1ed",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Month 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 45213.50it/s]\n",
            "Month 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 44038.81it/s]\n",
            "Month 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 43842.34it/s]\n",
            "Month 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 44184.38it/s]\n",
            "Month 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 45171.55it/s]\n",
            "Month 06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 42651.31it/s]\n",
            "Month 07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 43011.65it/s]\n",
            "Month 08: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 42521.71it/s]\n",
            "Month 09: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 42365.40it/s]\n",
            "Month 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 43639.89it/s]\n",
            "Month 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 42781.96it/s]\n",
            "Month 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 42999.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Finished sampling all monthly rasters.\n",
            "üíæ Saved seasonal climatology to ../data/features/grid_tmax.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Month 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 43538.56it/s]\n",
            "Month 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 43149.96it/s]\n",
            "Month 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 39223.27it/s]\n",
            "Month 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 40567.53it/s]\n",
            "Month 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 42007.67it/s]\n",
            "Month 06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 41178.51it/s]\n",
            "Month 07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 41546.30it/s]\n",
            "Month 08: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 41867.68it/s]\n",
            "Month 09: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 41347.09it/s]\n",
            "Month 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 40320.14it/s]\n",
            "Month 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 43494.75it/s]\n",
            "Month 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 43950.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Finished sampling all monthly rasters.\n",
            "üíæ Saved seasonal climatology to ../data/features/grid_tmin.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Month 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 43389.21it/s]\n",
            "Month 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 44595.65it/s]\n",
            "Month 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 45086.13it/s]\n",
            "Month 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 44483.91it/s]\n",
            "Month 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 44052.66it/s]\n",
            "Month 06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 44059.83it/s]\n",
            "Month 07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 44705.43it/s]\n",
            "Month 08: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 36930.61it/s]\n",
            "Month 09: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 40934.17it/s]\n",
            "Month 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 43548.85it/s]\n",
            "Month 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 43743.43it/s]\n",
            "Month 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:05<00:00, 42983.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Finished sampling all monthly rasters.\n",
            "üíæ Saved seasonal climatology to ../data/features/grid_tprec.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Organize the files\n",
        "monthly_tmax_data = organize_monthly_climat_files(\n",
        "    \"../data/climate_dataset/5min/max/*.tif\"\n",
        ")\n",
        "monthly_tmin_data = organize_monthly_climat_files(\n",
        "    \"../data/climate_dataset/5min/min/*.tif\"\n",
        ")\n",
        "monthly_tprec_data = organize_monthly_climat_files(\n",
        "    \"../data/climate_dataset/5min/prec/*.tif\"\n",
        ")\n",
        "\n",
        "\n",
        "extract_features_monthly_clim(\n",
        "    point_csv=\"../data/features/grid_points.csv\",\n",
        "    raster_dict=monthly_tmax_data,\n",
        "    output_path=\"../data/features/grid_tmax.csv\",\n",
        "    col_name=\"tmax\",\n",
        ")\n",
        "\n",
        "\n",
        "extract_features_monthly_clim(\n",
        "    point_csv=\"../data/features/grid_points.csv\",\n",
        "    raster_dict=monthly_tmin_data,\n",
        "    output_path=\"../data/features/grid_tmin.csv\",\n",
        "    col_name=\"tmin\",\n",
        ")\n",
        "\n",
        "\n",
        "extract_features_monthly_clim(\n",
        "    point_csv=\"../data/features/grid_points.csv\",\n",
        "    raster_dict=monthly_tprec_data,\n",
        "    output_path=\"../data/features/grid_tprec.csv\",\n",
        "    col_name=\"prec\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cd545be",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Season</th>\n",
              "      <th>Count</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Winter</td>\n",
              "      <td>18609</td>\n",
              "      <td>20.62%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spring</td>\n",
              "      <td>23093</td>\n",
              "      <td>25.59%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Summer</td>\n",
              "      <td>24667</td>\n",
              "      <td>27.33%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Autumn/Fall</td>\n",
              "      <td>23881</td>\n",
              "      <td>26.46%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Season  Count Percentage\n",
              "3       Winter  18609     20.62%\n",
              "2       Spring  23093     25.59%\n",
              "0       Summer  24667     27.33%\n",
              "1  Autumn/Fall  23881     26.46%"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calculate_seasonal_fire_percentage('../data/fire_dataset/viirs-jpss1_2024_alg_Tun.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8df16c36",
      "metadata": {},
      "source": [
        "### üìä Seasonal Fire Distribution\n",
        "üî• As we can see, fires occur almost equally across all seasons\n",
        "\n",
        "‚ö†Ô∏è Therefore, dropping any season‚Äôs climat data is not advisable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7878f9c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values (percent) per column :\n",
            "winter_tmax    0.356743\n",
            "spring_tmax    0.356743\n",
            "summer_tmax    0.356743\n",
            "autumn_tmax    0.356743\n",
            "dtype: float64\n",
            "\n",
            "=== Imputing column: winter_tmax ===\n",
            "winter_tmax: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: spring_tmax ===\n",
            "spring_tmax: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: summer_tmax ===\n",
            "summer_tmax: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: autumn_tmax ===\n",
            "autumn_tmax: imputation done using geo-zones.\n",
            "üíæ Saved imputation to ../data/features_cleaned/grid_tmax_clean.csv\n",
            "Saved preprocessed dataset ‚Üí ../data/preprocessed/tmax_preprocessed.csv\n",
            "Missing values (percent) per column :\n",
            "winter_tmin    0.356743\n",
            "spring_tmin    0.356743\n",
            "summer_tmin    0.356743\n",
            "autumn_tmin    0.356743\n",
            "dtype: float64\n",
            "\n",
            "=== Imputing column: winter_tmin ===\n",
            "winter_tmin: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: spring_tmin ===\n",
            "spring_tmin: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: summer_tmin ===\n",
            "summer_tmin: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: autumn_tmin ===\n",
            "autumn_tmin: imputation done using geo-zones.\n",
            "üíæ Saved imputation to ../data/features_cleaned/grid_tmin_clean.csv\n",
            "Saved preprocessed dataset ‚Üí ../data/preprocessed/tmin_preprocessed.csv\n",
            "Missing values (percent) per column :\n",
            "winter_prec    0.356743\n",
            "spring_prec    0.356743\n",
            "summer_prec    0.356743\n",
            "autumn_prec    0.356743\n",
            "dtype: float64\n",
            "\n",
            "=== Imputing column: winter_prec ===\n",
            "winter_prec: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: spring_prec ===\n",
            "spring_prec: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: summer_prec ===\n",
            "summer_prec: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: autumn_prec ===\n",
            "autumn_prec: imputation done using geo-zones.\n",
            "üíæ Saved imputation to ../data/features_cleaned/grid_prec_clean.csv\n",
            "Saved preprocessed dataset ‚Üí ../data/preprocessed/prec_preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "impute_with_geo_zones(\"../data/features/grid_tmax.csv\", base_res=0.05 , min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_tmax_clean.csv\")\n",
        "scalingEncodingDataset(\"../data/features_cleaned/grid_tmax_clean.csv\",\"../data/preprocessed/tmax_preprocessed.csv\")\n",
        "\n",
        "impute_with_geo_zones(\"../data/features/grid_tmin.csv\", base_res=0.05, min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_tmin_clean.csv\")\n",
        "scalingEncodingDataset(\"../data/features_cleaned/grid_tmin_clean.csv\",\"../data/preprocessed/tmin_preprocessed.csv\")\n",
        "\n",
        "\n",
        "impute_with_geo_zones(\"../data/features/grid_tprec.csv\", base_res=0.05 , min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_prec_clean.csv\")\n",
        "scalingEncodingDataset(\"../data/features_cleaned/grid_prec_clean.csv\",\"../data/preprocessed/prec_preprocessed.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbc5402e",
      "metadata": {},
      "source": [
        "## üå≥ Landcover Dataset\n",
        "\n",
        "üå± Extract landcover values from the reference grid\n",
        "\n",
        "üõ†Ô∏è Preprocess by handling missing values using the median Applying regional resolution\n",
        "\n",
        "üìè Scale features using a Robust Scaler\n",
        "\n",
        "‚úÖ We only kept the gridcode feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea9ededd",
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_features_landcover(\n",
        "    csv_path=\"../data/features/grid_points.csv\",\n",
        "    shapefile_path=\"../data/land_dataset/combined/alg_tun_landcvr.shp\",\n",
        "    lat_col=\"latitude\",\n",
        "    lon_col=\"longitude\",\n",
        "    keep_cols=[\"GRIDCODE\"],  # can be [\"GRIDCODE\", \"CLASS\", \"AREA\", ...]\n",
        "    output_path=\"../data/features/grid_landcover.csv\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a4c3b43",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values (percent) per column :\n",
            "GRIDCODE    0.051591\n",
            "dtype: float64\n",
            "\n",
            "=== Imputing column: GRIDCODE ===\n",
            "GRIDCODE: imputation done using geo-zones.\n",
            "üíæ Saved imputation to ../data/features_cleaned/grid_landcover_clean.csv\n",
            "Saved preprocessed dataset ‚Üí ../data/preprocessed/landcover_preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "impute_with_geo_zones(\"../data/features/grid_landcover.csv\", base_res=0.05, min_points=10 ,max_res=0.2, output_path=\"../data/features_cleaned/grid_landcover_clean.csv\")\n",
        "scalingEncodingDataset(\"../data/features_cleaned/grid_landcover_clean.csv\",\"../data/preprocessed/landcover_preprocessed.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d2792ed",
      "metadata": {},
      "source": [
        "## üå± Soil Dataset\n",
        "\n",
        "üß± Extract soil features from the reference grid\n",
        "\n",
        "üõ†Ô∏è Preprocess missing and invalid data\n",
        "\n",
        "Rows with negative values (likely sensor errors) are treated as missing Apply regional resolution\n",
        "\n",
        "üé® Feature selection & encoding\n",
        "\n",
        "TEXTURE_SOTER and TEXTURE_USDA have the same meaning\n",
        "\n",
        "Keep only TEXTURE_USDA (more detailed)\n",
        "\n",
        "Apply One-Hot Encoding to TEXTURE_USDA\n",
        "\n",
        "üìè Scale features using a Robust Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c402a119",
      "metadata": {},
      "outputs": [],
      "source": [
        "extract_features_soil(\n",
        "    csv_path=\"../data/features/grid_points.csv\",\n",
        "    raster_path=\"../data/soil_dataset/original/HWSD2_RASTER/HWSD2.bil\",\n",
        "    soil_attributes_csv=\"../data/soil_dataset/simplified/D1_soil_features_alg_tun.csv\",\n",
        "    output_soil_ids=\"../data/features/fire_soil_ids.csv\",\n",
        "    output_soil_feature=\"../data/features/grid_soil.csv\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "64b5849f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"../data/features/grid_soil.csv\")\n",
        "if \"TEXTURE_SOTER\" in df.columns:\n",
        "        df.drop(columns=[\"TEXTURE_SOTER\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dd9d87d3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úî Cleaning complete!\n",
            "  Deleted rows : 15998\n",
            "  Fixed rows   : 21237\n"
          ]
        }
      ],
      "source": [
        "treat_sensor_errors_soil(\"../data/features/grid_soil.csv\",output_path=\"../data/features/grid_soil_treated.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "df16c23d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values (percent) per column :\n",
            "COARSE          11.772825\n",
            "SAND            11.772825\n",
            "SILT            11.772825\n",
            "CLAY            11.772825\n",
            "TEXTURE_USDA    11.772825\n",
            "BULK            11.772825\n",
            "REF_BULK        11.772825\n",
            "ORG_CARBON      11.772825\n",
            "PH_WATER        11.772825\n",
            "TOTAL_N         11.772825\n",
            "CN_RATIO        11.772825\n",
            "CEC_SOIL        11.772825\n",
            "CEC_CLAY        11.772825\n",
            "CEC_EFF         11.772825\n",
            "TEB             11.772825\n",
            "BSAT            11.772825\n",
            "ALUM_SAT        11.772825\n",
            "ESP             11.772825\n",
            "TCARBON_EQ      11.772825\n",
            "GYPSUM          11.772825\n",
            "ELEC_COND       11.772825\n",
            "dtype: float64\n",
            "\n",
            "=== Imputing column: COARSE ===\n",
            "COARSE: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: SAND ===\n",
            "SAND: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: SILT ===\n",
            "SILT: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: CLAY ===\n",
            "CLAY: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: TEXTURE_USDA ===\n",
            "TEXTURE_USDA: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: BULK ===\n",
            "BULK: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: REF_BULK ===\n",
            "REF_BULK: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: ORG_CARBON ===\n",
            "ORG_CARBON: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: PH_WATER ===\n",
            "PH_WATER: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: TOTAL_N ===\n",
            "TOTAL_N: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: CN_RATIO ===\n",
            "CN_RATIO: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: CEC_SOIL ===\n",
            "CEC_SOIL: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: CEC_CLAY ===\n",
            "CEC_CLAY: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: CEC_EFF ===\n",
            "CEC_EFF: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: TEB ===\n",
            "TEB: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: BSAT ===\n",
            "BSAT: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: ALUM_SAT ===\n",
            "ALUM_SAT: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: ESP ===\n",
            "ESP: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: TCARBON_EQ ===\n",
            "TCARBON_EQ: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: GYPSUM ===\n",
            "GYPSUM: imputation done using geo-zones.\n",
            "\n",
            "=== Imputing column: ELEC_COND ===\n",
            "ELEC_COND: imputation done using geo-zones.\n",
            "üíæ Saved imputation to ../data/features_cleaned/grid_soil_clean.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "CATEGORICAL_COLS_SOIL = [\"TEXTURE_USDA\"]  # categorical columns\n",
        "NUMERIC_COLS_SOIL = [\n",
        "    \"COARSE\", \"SAND\", \"SILT\", \"CLAY\", \"BULK\", \"REF_BULK\", \"ORG_CARBON\", \"PH_WATER\",\n",
        "    \"TOTAL_N\", \"CN_RATIO\", \"CEC_SOIL\", \"CEC_CLAY\", \"CEC_EFF\", \"TEB\", \"BSAT\",\n",
        "    \"ALUM_SAT\", \"ESP\", \"TCARBON_EQ\", \"GYPSUM\", \"ELEC_COND\"\n",
        "]  # numeric columns\n",
        "\n",
        "# Usage\n",
        "soil_cleaned = impute_with_geo_zones(\"../data/features/grid_soil_treated.csv\",num_cols=NUMERIC_COLS_SOIL , cat_cols=CATEGORICAL_COLS_SOIL,  base_res=0.05, min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_soil_clean.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2c0c46c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEXTURE_USDA classes found: [np.int64(3), np.int64(5), np.int64(7), np.int64(9), np.int64(10), np.int64(11), np.int64(12)]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved preprocessed dataset ‚Üí ../data/preprocessed/soil_preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "scalingEncodingDataset(\"../data/features_cleaned/grid_soil_clean.csv\",\"../data/preprocessed/soil_preprocessed.csv\",categorical_col=[\"TEXTURE_USDA\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e573fbbf",
      "metadata": {},
      "source": [
        "## üèîÔ∏è Elevation Dataset\n",
        "\n",
        "üóª Extract elevation values from the reference grid\n",
        "\n",
        "üõ†Ô∏è Preprocess by handling missing values using the median\n",
        "\n",
        "üåç Apply regional resolution if needed\n",
        "\n",
        "üìè Scale features using a Robust Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "692b10cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 253077 points from ../data/features/grid_points.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting elevation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:06<00:00, 38504.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved extracted elevation to ../data/features/grid_elevation.csv\n"
          ]
        }
      ],
      "source": [
        "fires_with_elevation = extract_features_elevation(\n",
        "    raster_path=\"../data/elevation_dataset/simplified/elevation_clipped.tif\",\n",
        "    fire_csv_path=\"../data/features/grid_points.csv\",\n",
        "    output_csv=\"../data/features/grid_elevation.csv\",\n",
        "    value_name=\"elevation\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "038afea2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values (percent) per column :\n",
            "Series([], dtype: float64)\n",
            "üíæ Saved imputation to ../data/features_cleaned/grid_elevation_clean.csv\n",
            "Saved preprocessed dataset ‚Üí ../data/preprocessed/elevation_preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "impute_with_geo_zones(\"../data/features/grid_elevation.csv\", base_res=0.05, min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_elevation_clean.csv\")\n",
        "scalingEncodingDataset(\"../data/features_cleaned/grid_elevation_clean.csv\",\"../data/preprocessed/elevation_preprocessed.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fce3326",
      "metadata": {},
      "source": [
        "## üìä Merging Preprocessed Datasets\n",
        "Merging all preprocessed datasets on the common key fields of longitude and latitude to obtain one final, unified dataset for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "12bdab4a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading first CSV: ../data/preprocessed/tmax_preprocessed.csv\n",
            "üîÅ Merging file 2/7: ../data/preprocessed/tmin_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (253077, 10)\n",
            "üîÅ Merging file 3/7: ../data/preprocessed/prec_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (253077, 14)\n",
            "üîÅ Merging file 4/7: ../data/preprocessed/landcover_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (253077, 15)\n",
            "üîÅ Merging file 5/7: ../data/preprocessed/elevation_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (253077, 16)\n",
            "üîÅ Merging file 6/7: ../data/preprocessed/soil_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (501201, 43)\n",
            "üîÅ Merging file 7/7: ../data/preprocessed/fire_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (501201, 44)\n",
            "‚úÖ Intermediate merged size: (91102, 10)\n",
            "üîÅ Merging file 3/7: ../data/preprocessed/prec_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (91102, 14)\n",
            "üîÅ Merging file 4/7: ../data/preprocessed/landcover_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (91102, 15)\n",
            "üîÅ Merging file 5/7: ../data/preprocessed/elevation_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (91102, 16)\n",
            "üîÅ Merging file 6/7: ../data/preprocessed/soil_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (180407, 43)\n",
            "üîÅ Merging file 7/7: ../data/preprocessed/fire_preprocessed.csv\n",
            "‚úÖ Intermediate merged size: (180407, 44)\n",
            "‚úÖ All files merged successfully.\n"
          ]
        }
      ],
      "source": [
        "csv_list= [\"../data/preprocessed/tmax_preprocessed.csv\", \"../data/preprocessed/tmin_preprocessed.csv\",\"../data/preprocessed/prec_preprocessed.csv\",  \"../data/preprocessed/landcover_preprocessed.csv\" , \"../data/preprocessed/elevation_preprocessed.csv\" , \"../data/preprocessed/soil_preprocessed.csv\",\"../data/preprocessed/fire_preprocessed.csv\"]\n",
        "temp_df = progressive_merge(\n",
        "    csv_list,\n",
        "    on=[\"latitude\", \"longitude\"],\n",
        "    how=\"inner\",\n",
        "    output_path=\"../data/Merged/merged.csv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9dce0bc",
      "metadata": {},
      "source": [
        "## üìâ Feature Reduction Analysis\n",
        "\n",
        "üìä Visualize feature variance\n",
        "\n",
        "Sort features by descending variance to identify those that contribute most\n",
        "\n",
        "üîé Very low-variance features carry little information and can be removed\n",
        "\n",
        "üîó Check highly correlated features\n",
        "\n",
        "Detect pairs with high correlation (above a chosen threshold)\n",
        "\n",
        "üîÅ Highly correlated features bring redundant information, so one of them can be safely dropped\n",
        "\n",
        "üå≤ Random Forest Feature Selection\n",
        "\n",
        "Apply a Random Forest model to rank feature importance\n",
        "\n",
        "Keep only the top 30 features for a cleaner and more efficient dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3d6d1cc9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlated pairs:\n",
            "('spring_tmax', 'winter_tmax', np.float64(0.9701794282727185))\n",
            "('spring_tmax', 'spring_tmin', np.float64(0.9676979443495476))\n",
            "('summer_tmax', 'summer_tmin', np.float64(0.9536212160267433))\n",
            "('autumn_tmax', 'spring_tmax', np.float64(0.962601490124305))\n",
            "('autumn_tmax', 'autumn_tmin', np.float64(0.9597141933382659))\n",
            "('spring_tmin', 'winter_tmax', np.float64(0.9570075571033595))\n",
            "('CLAY', 'REF_BULK', np.float64(0.9507190892777528))\n",
            "('CEC_EFF', 'TEB', np.float64(0.9679953726774849))\n",
            "('ELEC_COND', 'ESP', np.float64(0.9732572534215913))\n",
            "\n",
            "Feature variances:\n",
            "TEX_7             0.000231\n",
            "TEX_10            0.005147\n",
            "TEX_3             0.006356\n",
            "TEX_12            0.013442\n",
            "TEX_5             0.048553\n",
            "TEX_9             0.227777\n",
            "TEX_11            0.244748\n",
            "SAND              0.326281\n",
            "PH_WATER          0.327138\n",
            "SILT              0.351126\n",
            "CEC_CLAY          0.352937\n",
            "BULK              0.448883\n",
            "winter_tmin       0.476771\n",
            "summer_tmax       0.553706\n",
            "CN_RATIO          0.594191\n",
            "BSAT              0.625526\n",
            "COARSE            0.631119\n",
            "elevation         0.715001\n",
            "winter_tmax       0.758266\n",
            "ALUM_SAT          0.770996\n",
            "summer_prec       0.815097\n",
            "summer_tmin       0.827521\n",
            "spring_tmin       0.837865\n",
            "TCARBON_EQ        0.860396\n",
            "spring_tmax       0.906631\n",
            "REF_BULK          0.992217\n",
            "autumn_tmin       1.001259\n",
            "autumn_tmax       1.004161\n",
            "CEC_SOIL          1.136070\n",
            "TEB               1.164256\n",
            "CLAY              1.229020\n",
            "TOTAL_N           1.282474\n",
            "autumn_prec       2.211899\n",
            "CEC_EFF           2.481050\n",
            "spring_prec       4.136424\n",
            "GYPSUM            4.902434\n",
            "ORG_CARBON        9.754947\n",
            "ELEC_COND        12.945819\n",
            "winter_prec      28.503400\n",
            "ESP             154.054121\n",
            "GRIDCODE       2333.772653\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "res = analyze_correlation_variance(\"../data/Merged/merged.csv\" ,target_col=\"fire\", corr_threshold=0.95,)\n",
        "\n",
        "print(\"Correlated pairs:\")\n",
        "for p in res[\"correlated_pairs\"]:\n",
        "    print(p)\n",
        "\n",
        "print(\"\\nFeature variances:\")\n",
        "print(res[\"variances\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "292140d2",
      "metadata": {},
      "source": [
        "## Remove southern desert data points "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "156a93aa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shape: (501201, 44)\n"
          ]
        }
      ],
      "source": [
        "df_cleaned = pd.read_csv(\"../data/Merged/merged.csv\")\n",
        "print(\"Original shape:\", df_cleaned.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e57ca71b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(124104, 44)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_filtered = df_cleaned[df_cleaned['latitude'] >= 33]\n",
        "print(df_filtered.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e32f2422",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save filtered DataFrame to a new CSV\n",
        "df_filtered.to_csv('../data/Merged/merge_north.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "19651ef8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected features: ['elevation', 'GRIDCODE', 'spring_prec', 'summer_prec', 'autumn_prec', 'winter_prec', 'summer_tmax', 'autumn_tmax', 'spring_tmax', 'winter_tmax', 'winter_tmin', 'summer_tmin', 'ORG_CARBON', 'CEC_CLAY', 'GYPSUM', 'BSAT', 'PH_WATER', 'SAND', 'SILT', 'BULK', 'TCARBON_EQ', 'TOTAL_N', 'COARSE', 'CEC_SOIL', 'CN_RATIO', 'ESP', 'ELEC_COND', 'TEX_5', 'TEX_9', 'ALUM_SAT']\n"
          ]
        }
      ],
      "source": [
        "reduced = reduce_features(\n",
        "    \"../data/Merged/merge_north.csv\",\n",
        "    output_path=\"../data/Merged/reduced_North_data.csv\",\n",
        "    var_threshold=0.01,\n",
        "    corr_threshold=0.95,\n",
        "    importance_method=\"RF\",\n",
        "    top_k=30\n",
        ")\n",
        "\n",
        "print(\"Selected features:\", reduced[\"selected_features\"])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
>>>>>>> mrwn
}
