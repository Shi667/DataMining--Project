{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859f5f99",
   "metadata": {},
   "source": [
    "# üß™ Work Overview\n",
    "\n",
    "In this work, we will:\n",
    "\n",
    "üßº Clean and preprocess multiple datasets (elevation, soil, climate, etc.)\n",
    "\n",
    "üîó Merge them into a single unified dataset\n",
    "\n",
    "üîç Run tests to check whether feature reduction is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c71268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.dataMerging.combineDatasets import extract_features_elevation , extract_features_landcover , extract_features_monthly_clim , extract_features_soil , organize_monthly_climat_files\n",
    "from scripts.dataMerging.mergeDataSources import progressive_merge\n",
    "from scripts.dataMerging.generateGrid import generate_grid_in_shape\n",
    "from scripts.dataPreprocessing.dataCleaning import process_fire_data , treat_sensor_errors_soil , impute_with_geo_zones \n",
    "from scripts.dataPreprocessing.scalingEncoding import scalingEncodingDataset\n",
    "from scripts.statistics.firePerSeason import calculate_seasonal_fire_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92275cd4",
   "metadata": {},
   "source": [
    "### üó∫Ô∏è Reference Grid\n",
    "\n",
    "üìê Create a reference grid with consistent latitude and longitude\n",
    "\n",
    "üîó Ensures all datasets align and can be merged correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e89d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading shapefile...\n",
      "üó∫Ô∏è Bounding box: [-8.67386818 18.96023083 11.98736715 37.55986   ]\n",
      "üìè Grid: 689 √ó 620 = 427,180 total potential points\n",
      "üîç Filtering points inside region...\n",
      "‚úÖ 253,077 points inside shapefile\n",
      "üíæ Saved grid to ../data/features/grid_points.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Generate grid (only once)\n",
    "grid_df = generate_grid_in_shape(\n",
    "    \"../data/shapefiles/combined/alg_tun.shp\",\n",
    "    resolution=0.01, # 1 KM resolution\n",
    "    output_csv=\"../data/features/grid_points.csv\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d8cf15",
   "metadata": {},
   "source": [
    "## üî• Extract Nearest Points (cKDTree)\n",
    "\n",
    "üå≥ Use cKDTree to find the nearest grid point for each fire record\n",
    "\n",
    "üìç Matches fire locations to the reference grid efficiently\n",
    "\n",
    "‚ö° Fast nearest-neighbor search for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb16ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved (253077, 3) grid points with binary fire data (1/0) to ../data/preprocessed/fire_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the paths and parameters\n",
    "GRID_FILE = \"../data/features/grid_points.csv\"\n",
    "FIRE_FILE = \"../data/fire_dataset/viirs-jpss1_2024_alg_Tun.csv\"\n",
    "TARGET_FIRE_TYPE = 2 \n",
    "\n",
    "process_fire_data(\n",
    "    grid_path=GRID_FILE,\n",
    "    fire_path=FIRE_FILE,\n",
    "    target_type=TARGET_FIRE_TYPE,\n",
    "    output_file=\"../data/preprocessed/fire_preprocessed.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d434e06",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Climat Dataset\n",
    "\n",
    "‚ùÑÔ∏è Extract seasonal data (winter, spring, summer, autumn)\n",
    "\n",
    "üõ†Ô∏è Preprocess by fixing missing values using the median Apply regional resolution \n",
    "\n",
    "üìè Scale features using a Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afbf1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Month 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:59<00:00, 4220.63it/s]\n",
      "Month 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [01:00<00:00, 4198.97it/s]\n",
      "Month 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:50<00:00, 5060.32it/s]\n",
      "Month 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [01:04<00:00, 3913.41it/s]\n",
      "Month 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:45<00:00, 5558.18it/s]\n",
      "Month 06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:52<00:00, 4863.49it/s]\n",
      "Month 07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:45<00:00, 5558.98it/s]\n",
      "Month 08: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:43<00:00, 5768.20it/s]\n",
      "Month 09: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:45<00:00, 5536.26it/s]\n",
      "Month 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:46<00:00, 5454.37it/s]\n",
      "Month 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:41<00:00, 6064.51it/s]\n",
      "Month 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:46<00:00, 5394.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished sampling all monthly rasters.\n",
      "üíæ Saved seasonal climatology to ../data/features/grid_tmax.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Month 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:34<00:00, 7300.84it/s]\n",
      "Month 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:44<00:00, 5632.35it/s]\n",
      "Month 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:54<00:00, 4657.10it/s]\n",
      "Month 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:47<00:00, 5357.38it/s]\n",
      "Month 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:48<00:00, 5176.74it/s]\n",
      "Month 06: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:46<00:00, 5390.80it/s]\n",
      "Month 07: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:51<00:00, 4918.42it/s]\n",
      "Month 08: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:34<00:00, 7384.47it/s]\n",
      "Month 09: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:31<00:00, 8042.89it/s]\n",
      "Month 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:41<00:00, 6036.46it/s]\n",
      "Month 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:45<00:00, 5591.45it/s]\n",
      "Month 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:42<00:00, 5944.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished sampling all monthly rasters.\n",
      "üíæ Saved seasonal climatology to ../data/features/grid_tmin.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Month 01: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:46<00:00, 5415.44it/s]\n",
      "Month 02: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:38<00:00, 6655.01it/s]\n",
      "Month 03: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:49<00:00, 5128.33it/s]\n",
      "Month 04: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:41<00:00, 6156.65it/s]\n",
      "Month 05: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 253077/253077 [00:51<00:00, 4958.63it/s]\n",
      "Month 06:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 173508/253077 [00:33<00:26, 3028.27it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Organize the files\n",
    "monthly_tmax_data = organize_monthly_climat_files(\n",
    "    \"../data/climate_dataset/5min/max/*.tif\"\n",
    ")\n",
    "monthly_tmin_data = organize_monthly_climat_files(\n",
    "    \"../data/climate_dataset/5min/min/*.tif\"\n",
    ")\n",
    "monthly_tprec_data = organize_monthly_climat_files(\n",
    "    \"../data/climate_dataset/5min/prec/*.tif\"\n",
    ")\n",
    "\n",
    "\n",
    "extract_features_monthly_clim(\n",
    "    point_csv=\"../data/features/grid_points.csv\",\n",
    "    raster_dict=monthly_tmax_data,\n",
    "    output_path=\"../data/features/grid_tmax.csv\",\n",
    "    col_name=\"tmax\",\n",
    ")\n",
    "\n",
    "\n",
    "extract_features_monthly_clim(\n",
    "    point_csv=\"../data/features/grid_points.csv\",\n",
    "    raster_dict=monthly_tmin_data,\n",
    "    output_path=\"../data/features/grid_tmin.csv\",\n",
    "    col_name=\"tmin\",\n",
    ")\n",
    "\n",
    "\n",
    "extract_features_monthly_clim(\n",
    "    point_csv=\"../data/features/grid_points.csv\",\n",
    "    raster_dict=monthly_tprec_data,\n",
    "    output_path=\"../data/features/grid_tprec.csv\",\n",
    "    col_name=\"prec\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd545be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>18609</td>\n",
       "      <td>20.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spring</td>\n",
       "      <td>23093</td>\n",
       "      <td>25.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer</td>\n",
       "      <td>24667</td>\n",
       "      <td>27.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autumn/Fall</td>\n",
       "      <td>23881</td>\n",
       "      <td>26.46%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Season  Count Percentage\n",
       "3       Winter  18609     20.62%\n",
       "2       Spring  23093     25.59%\n",
       "0       Summer  24667     27.33%\n",
       "1  Autumn/Fall  23881     26.46%"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_seasonal_fire_percentage('../data/fire_dataset/viirs-jpss1_2024_alg_Tun.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df16c36",
   "metadata": {},
   "source": [
    "### üìä Seasonal Fire Distribution\n",
    "üî• As we can see, fires occur almost equally across all seasons\n",
    "\n",
    "‚ö†Ô∏è Therefore, dropping any season‚Äôs climat data is not advisable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7878f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (percent) per column :\n",
      "winter_tmax    0.356743\n",
      "spring_tmax    0.356743\n",
      "summer_tmax    0.356743\n",
      "autumn_tmax    0.356743\n",
      "dtype: float64\n",
      "\n",
      "=== Imputing column: winter_tmax ===\n",
      "winter_tmax: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_tmax_clean.csv\n",
      "\n",
      "=== Imputing column: spring_tmax ===\n",
      "spring_tmax: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_tmax_clean.csv\n",
      "\n",
      "=== Imputing column: summer_tmax ===\n",
      "summer_tmax: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_tmax_clean.csv\n",
      "\n",
      "=== Imputing column: autumn_tmax ===\n",
      "autumn_tmax: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_tmax_clean.csv\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/tmax_preprocessed.csv\n",
      "Missing values (percent) per column :\n",
      "winter_tmin    0.356743\n",
      "spring_tmin    0.356743\n",
      "summer_tmin    0.356743\n",
      "autumn_tmin    0.356743\n",
      "dtype: float64\n",
      "\n",
      "=== Imputing column: winter_tmin ===\n",
      "winter_tmin: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_tmin_clean.csv\n",
      "\n",
      "=== Imputing column: spring_tmin ===\n",
      "spring_tmin: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_tmin_clean.csv\n",
      "\n",
      "=== Imputing column: summer_tmin ===\n",
      "summer_tmin: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_tmin_clean.csv\n",
      "\n",
      "=== Imputing column: autumn_tmin ===\n",
      "autumn_tmin: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_tmin_clean.csv\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/tmin_preprocessed.csv\n",
      "Missing values (percent) per column :\n",
      "winter_prec    0.356743\n",
      "spring_prec    0.356743\n",
      "summer_prec    0.356743\n",
      "autumn_prec    0.356743\n",
      "dtype: float64\n",
      "\n",
      "=== Imputing column: winter_prec ===\n",
      "winter_prec: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_prec_clean.csv\n",
      "\n",
      "=== Imputing column: spring_prec ===\n",
      "spring_prec: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_prec_clean.csv\n",
      "\n",
      "=== Imputing column: summer_prec ===\n",
      "summer_prec: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_prec_clean.csv\n",
      "\n",
      "=== Imputing column: autumn_prec ===\n",
      "autumn_prec: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_prec_clean.csv\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/prec_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "impute_with_geo_zones(\"../data/features/grid_tmax.csv\", base_res=0.05 , min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_tmax_clean.csv\")\n",
    "scalingEncodingDataset(\"../data/features_cleaned/grid_tmax_clean.csv\",\"../data/preprocessed/tmax_preprocessed.csv\")\n",
    "\n",
    "impute_with_geo_zones(\"../data/features/grid_tmin.csv\", base_res=0.05, min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_tmin_clean.csv\")\n",
    "scalingEncodingDataset(\"../data/features_cleaned/grid_tmin_clean.csv\",\"../data/preprocessed/tmin_preprocessed.csv\")\n",
    "\n",
    "\n",
    "impute_with_geo_zones(\"../data/features/grid_tprec.csv\", base_res=0.05 , min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_prec_clean.csv\")\n",
    "scalingEncodingDataset(\"../data/features_cleaned/grid_prec_clean.csv\",\"../data/preprocessed/prec_preprocessed.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5402e",
   "metadata": {},
   "source": [
    "## üå≥ Landcover Dataset\n",
    "\n",
    "üå± Extract landcover values from the reference grid\n",
    "\n",
    "üõ†Ô∏è Preprocess by handling missing values using the median Applying regional resolution\n",
    "\n",
    "üìè Scale features using a Robust Scaler\n",
    "\n",
    "‚úÖ We only kept the gridcode feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ededd",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features_landcover(\n",
    "    csv_path=\"../data/features/grid_points.csv\",\n",
    "    shapefile_path=\"../data/land_dataset/combined/alg_tun_landcvr.shp\",\n",
    "    lat_col=\"latitude\",\n",
    "    lon_col=\"longitude\",\n",
    "    keep_cols=[\"GRIDCODE\"],  # can be [\"GRIDCODE\", \"CLASS\", \"AREA\", ...]\n",
    "    output_path=\"../data/features/grid_landcover.csv\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c3b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (percent) per column :\n",
      "GRIDCODE    0.051591\n",
      "dtype: float64\n",
      "\n",
      "=== Imputing column: GRIDCODE ===\n",
      "GRIDCODE: imputation done using geo-zones.\n",
      "üíæ Saved imputation to ../data/features_cleaned/grid_landcover_clean.csv\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/landcover_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "impute_with_geo_zones(\"../data/features/grid_landcover.csv\", base_res=0.05, min_points=10 ,max_res=0.2, output_path=\"../data/features_cleaned/grid_landcover_clean.csv\")\n",
    "scalingEncodingDataset(\"../data/features_cleaned/grid_landcover_clean.csv\",\"../data/preprocessed/landcover_preprocessed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2792ed",
   "metadata": {},
   "source": [
    "## üå± Soil Dataset\n",
    "\n",
    "üß± Extract soil features from the reference grid\n",
    "\n",
    "üõ†Ô∏è Preprocess missing and invalid data\n",
    "\n",
    "Rows with negative values (likely sensor errors) are treated as missing Apply regional resolution\n",
    "\n",
    "üé® Feature selection & encoding\n",
    "\n",
    "TEXTURE_SOTER and TEXTURE_USDA have the same meaning\n",
    "\n",
    "Keep only TEXTURE_USDA (more detailed)\n",
    "\n",
    "Apply One-Hot Encoding to TEXTURE_USDA\n",
    "\n",
    "üìè Scale features using a Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features_soil(\n",
    "    csv_path=\"../data/features/grid_points.csv\",\n",
    "    raster_path=\"../data/soil_dataset/original/HWSD2_RASTER/HWSD2.bil\",\n",
    "    soil_attributes_csv=\"../data/soil_dataset/simplified/D1_soil_features_alg_tun.csv\",\n",
    "    output_soil_ids=\"../data/features/fire_soil_ids.csv\",\n",
    "    output_soil_feature=\"../data/features/grid_soil.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/features/grid_soil.csv\")\n",
    "if \"TEXTURE_SOTER\" in df.columns:\n",
    "        df.drop(columns=[\"TEXTURE_SOTER\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Cleaning complete!\n",
      "  Deleted rows : 15998\n",
      "  Fixed rows   : 21237\n"
     ]
    }
   ],
   "source": [
    "treat_sensor_errors_soil(\"../data/features/grid_soil.csv\",output_path=\"../data/features/grid_soil_treated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (percent) per column :\n",
      "COARSE          11.772825\n",
      "SAND            11.772825\n",
      "SILT            11.772825\n",
      "CLAY            11.772825\n",
      "TEXTURE_USDA    11.772825\n",
      "BULK            11.772825\n",
      "REF_BULK        11.772825\n",
      "ORG_CARBON      11.772825\n",
      "PH_WATER        11.772825\n",
      "TOTAL_N         11.772825\n",
      "CN_RATIO        11.772825\n",
      "CEC_SOIL        11.772825\n",
      "CEC_CLAY        11.772825\n",
      "CEC_EFF         11.772825\n",
      "TEB             11.772825\n",
      "BSAT            11.772825\n",
      "ALUM_SAT        11.772825\n",
      "ESP             11.772825\n",
      "TCARBON_EQ      11.772825\n",
      "GYPSUM          11.772825\n",
      "ELEC_COND       11.772825\n",
      "dtype: float64\n",
      "\n",
      "=== Imputing column: COARSE ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m NUMERIC_COLS_SOIL \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOARSE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAND\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSILT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLAY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBULK\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREF_BULK\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORG_CARBON\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPH_WATER\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOTAL_N\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCN_RATIO\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCEC_SOIL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCEC_CLAY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCEC_EFF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBSAT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALUM_SAT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mESP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTCARBON_EQ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGYPSUM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mELEC_COND\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m ]  \u001b[38;5;66;03m# numeric columns\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m soil_cleaned \u001b[38;5;241m=\u001b[39m \u001b[43mimpute_with_geo_zones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/features/grid_soil_treated.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUMERIC_COLS_SOIL\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCATEGORICAL_COLS_SOIL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mbase_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/features_cleaned/grid_soil_clean.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\src\\scripts\\dataPreprocessing\\dataCleaning.py:232\u001b[0m, in \u001b[0;36mimpute_with_geo_zones\u001b[1;34m(input_csv, num_cols, cat_cols, lat_col, lon_col, base_res, min_points, max_res, output_path)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Try expanding zone\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m resolution \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_res:\n\u001b[1;32m--> 232\u001b[0m     zone_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_zone_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(zone_df) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_points:\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\src\\scripts\\dataPreprocessing\\dataCleaning.py:200\u001b[0m, in \u001b[0;36mimpute_with_geo_zones.<locals>.get_zone_df\u001b[1;34m(lat, lon, res)\u001b[0m\n\u001b[0;32m    197\u001b[0m lat_min, lat_max \u001b[38;5;241m=\u001b[39m lat \u001b[38;5;241m-\u001b[39m res, lat \u001b[38;5;241m+\u001b[39m res\n\u001b[0;32m    198\u001b[0m lon_min, lon_max \u001b[38;5;241m=\u001b[39m lon \u001b[38;5;241m-\u001b[39m res, lon \u001b[38;5;241m+\u001b[39m res\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df[\n\u001b[1;32m--> 200\u001b[0m     (\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlat_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlat_min\u001b[49m)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;241m&\u001b[39m (df[lat_col] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lat_max)\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;241m&\u001b[39m (df[lon_col] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m lon_min)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;241m&\u001b[39m (df[lon_col] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lon_max)\n\u001b[0;32m    204\u001b[0m ]\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\pandas\\core\\arraylike.py:60\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\pandas\\core\\series.py:6138\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6135\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6136\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6138\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:347\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    222\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "CATEGORICAL_COLS_SOIL = [\"TEXTURE_USDA\"]  # categorical columns\n",
    "NUMERIC_COLS_SOIL = [\n",
    "    \"COARSE\", \"SAND\", \"SILT\", \"CLAY\", \"BULK\", \"REF_BULK\", \"ORG_CARBON\", \"PH_WATER\",\n",
    "    \"TOTAL_N\", \"CN_RATIO\", \"CEC_SOIL\", \"CEC_CLAY\", \"CEC_EFF\", \"TEB\", \"BSAT\",\n",
    "    \"ALUM_SAT\", \"ESP\", \"TCARBON_EQ\", \"GYPSUM\", \"ELEC_COND\"\n",
    "]  # numeric columns\n",
    "\n",
    "# Usage\n",
    "soil_cleaned = impute_with_geo_zones(\"../data/features/grid_soil_treated.csv\",num_cols=NUMERIC_COLS_SOIL , cat_cols=CATEGORICAL_COLS_SOIL,  base_res=0.05, min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_soil_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c46c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXTURE_USDA classes found: [np.int64(3), np.int64(5), np.int64(7), np.int64(9), np.int64(10), np.int64(11), np.int64(12)]\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/soil_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "scalingEncodingDataset(\"../data/features_cleaned/grid_soil_clean.csv\",\"../data/preprocessed/soil_preprocessed.csv\",categorical_col=[\"TEXTURE_USDA\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573fbbf",
   "metadata": {},
   "source": [
    "## üèîÔ∏è Elevation Dataset\n",
    "\n",
    "üóª Extract elevation values from the reference grid\n",
    "\n",
    "üõ†Ô∏è Preprocess by handling missing values using the median\n",
    "\n",
    "üåç Apply regional resolution if needed\n",
    "\n",
    "üìè Scale features using a Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b10cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 91102 points from ../data/features/grid_points.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting elevation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91102/91102 [00:13<00:00, 6933.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved extracted elevation to ../data/features/grid_elevation.csv\n"
     ]
    }
   ],
   "source": [
    "fires_with_elevation = extract_features_elevation(\n",
    "    raster_path=\"../data/elevation_dataset/simplified/elevation_clipped.tif\",\n",
    "    fire_csv_path=\"../data/features/grid_points.csv\",\n",
    "    output_csv=\"../data/features/grid_elevation.csv\",\n",
    "    value_name=\"elevation\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038afea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (percent) per column :\n",
      "Series([], dtype: float64)\n",
      "Saved preprocessed dataset ‚Üí ../data/preprocessed/elevation_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "impute_with_geo_zones(\"../data/features/grid_elevation.csv\", base_res=0.05, min_points=10 ,max_res=0.5, output_path=\"../data/features_cleaned/grid_elevation_clean.csv\")\n",
    "scalingEncodingDataset(\"../data/features_cleaned/grid_elevation_clean.csv\",\"../data/preprocessed/elevation_preprocessed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e714a4",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce3326",
   "metadata": {},
   "source": [
    "## üî• Merging with Fire Data üî•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bdab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading first CSV: ../data/features_cleaned/grid_tmax_clean.csv\n",
      "üîÅ Merging file 2/7: ../data/features_cleaned/grid_tmin_clean.csv\n",
      "‚úÖ Intermediate merged size: (91102, 10)\n",
      "üîÅ Merging file 3/7: ../data/features_cleaned/grid_tprec_clean.csv\n",
      "‚úÖ Intermediate merged size: (91102, 11)\n",
      "üîÅ Merging file 4/7: ../data/features_cleaned/grid_landcover_clean.csv\n",
      "‚úÖ Intermediate merged size: (91102, 12)\n",
      "üîÅ Merging file 5/7: ../data/features_cleaned/grid_elevation_clean.csv\n",
      "‚úÖ Intermediate merged size: (91102, 13)\n",
      "üîÅ Merging file 6/7: ../data/features_cleaned/grid_soil_clean.csv\n",
      "‚úÖ Intermediate merged size: (196405, 35)\n",
      "üîÅ Merging file 7/7: ../data/features_cleaned/grid_fire_clean.csv\n",
      "‚úÖ Intermediate merged size: (196405, 36)\n",
      "‚úÖ All files merged successfully.\n"
     ]
    }
   ],
   "source": [
    "csv_list= [\"../data/preprocessed/tmax_preprocessed.csv\", \"../data/preprocessed/tmin_preprocessed.csv\",\"../data/preprocessed/prec_preprocessed.csv\",  \"../data/preprocessed/landcover_preprocessed.csv\" , \"../data/preprocessed/elevation_preprocessed.csv\" , \"../data/preprocessed/soil_preprocessed.csv\",\"../data/preprocessed/fire_preprocessed.csv\"]\n",
    "temp_df = progressive_merge(\n",
    "    csv_list,\n",
    "    on=[\"latitude\", \"longitude\"],\n",
    "    how=\"inner\",\n",
    "    output_path=\"../data/Merged/merged.csv\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
