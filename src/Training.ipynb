{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e05f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts.data_split.stratifiedSplit import stratified_split\n",
    "from scripts.TreatImbalance.BalancingTrainingData import hybrid_balance\n",
    "from scripts.Training.TuneEvaluate import tune_and_evaluate \n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b35674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with shape: (735483, 41)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/preprocessed/preprocessed_reduced_data.csv\"\n",
    "\n",
    "target_col = \"fire\"\n",
    "test_size = 0.2\n",
    "desired_minority_prop = (\n",
    "        0.30  # user-chosen: 0.30 means 30% minority in balanced training set\n",
    "    )\n",
    "balanced_train_savepath = \"balanced_train.csv\"\n",
    "\n",
    "\n",
    "data_df = pd.read_csv(data_path)\n",
    "print(\"Loaded dataset with shape:\", data_df.shape)\n",
    "if target_col not in data_df.columns:\n",
    "        raise ValueError(\n",
    "            f\"Target column '{target_col}' not found in CSV columns: {data_df.columns.tolist()}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4214a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = stratified_split(\n",
    "        data_df, target_col=target_col, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ee270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 588386 (minority=49559, majority=538827)\n",
      "Desired minority proportion: 0.30\n",
      "Undersampling majority from 538827 -> 411870 (fast reduction).\n"
     ]
    }
   ],
   "source": [
    "balanced_train_df = hybrid_balance(\n",
    "        train_df,\n",
    "        target_col=target_col,\n",
    "        minority_target=1,\n",
    "        desired_minority_prop=desired_minority_prop,\n",
    "        random_state=42,\n",
    "        save_path=balanced_train_savepath,\n",
    "        verbose=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c18776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting GridSearchCV...\n",
      "\n",
      "\n",
      "=== Total combinations: 12 ===\n",
      "\n",
      "ðŸ”§ Running combination 1/12\n",
      "Params: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "-----------------------------------\n",
      "ðŸ“Œ Cross-validation metrics:\n",
      "   â€¢ Recall:    0.8808  Â± 0.0028\n",
      "   â€¢ Accuracy:  0.9698  Â± 0.0007\n",
      "   â€¢ Precision: 0.9993  Â± 0.0003\n",
      "   â€¢ F1-score:  0.9363  Â± 0.0016\n",
      "   â€¢ ROC AUC:   0.9688  Â± 0.0011\n",
      "-----------------------------------\n",
      "\n",
      "ðŸ”§ Running combination 2/12\n",
      "Params: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "-----------------------------------\n",
      "ðŸ“Œ Cross-validation metrics:\n",
      "   â€¢ Recall:    0.8808  Â± 0.0028\n",
      "   â€¢ Accuracy:  0.9698  Â± 0.0007\n",
      "   â€¢ Precision: 0.9993  Â± 0.0003\n",
      "   â€¢ F1-score:  0.9363  Â± 0.0016\n",
      "   â€¢ ROC AUC:   0.9688  Â± 0.0011\n",
      "-----------------------------------\n",
      "\n",
      "ðŸ”§ Running combination 3/12\n",
      "Params: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "-----------------------------------\n",
      "ðŸ“Œ Cross-validation metrics:\n",
      "   â€¢ Recall:    0.8808  Â± 0.0028\n",
      "   â€¢ Accuracy:  0.9699  Â± 0.0007\n",
      "   â€¢ Precision: 0.9992  Â± 0.0003\n",
      "   â€¢ F1-score:  0.9363  Â± 0.0016\n",
      "   â€¢ ROC AUC:   0.9689  Â± 0.0011\n",
      "-----------------------------------\n",
      "\n",
      "ðŸ”§ Running combination 4/12\n",
      "Params: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "-----------------------------------\n",
      "ðŸ“Œ Cross-validation metrics:\n",
      "   â€¢ Recall:    0.8808  Â± 0.0028\n",
      "   â€¢ Accuracy:  0.9699  Â± 0.0007\n",
      "   â€¢ Precision: 0.9992  Â± 0.0003\n",
      "   â€¢ F1-score:  0.9363  Â± 0.0016\n",
      "   â€¢ ROC AUC:   0.9689  Â± 0.0011\n",
      "-----------------------------------\n",
      "\n",
      "ðŸ”§ Running combination 5/12\n",
      "Params: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "-----------------------------------\n",
      "ðŸ“Œ Cross-validation metrics:\n",
      "   â€¢ Recall:    0.9267  Â± 0.0022\n",
      "   â€¢ Accuracy:  0.9813  Â± 0.0005\n",
      "   â€¢ Precision: 0.9991  Â± 0.0004\n",
      "   â€¢ F1-score:  0.9615  Â± 0.0011\n",
      "   â€¢ ROC AUC:   0.9824  Â± 0.0006\n",
      "-----------------------------------\n",
      "\n",
      "ðŸ”§ Running combination 6/12\n",
      "Params: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "-----------------------------------\n",
      "ðŸ“Œ Cross-validation metrics:\n",
      "   â€¢ Recall:    0.9267  Â± 0.0022\n",
      "   â€¢ Accuracy:  0.9813  Â± 0.0005\n",
      "   â€¢ Precision: 0.9991  Â± 0.0004\n",
      "   â€¢ F1-score:  0.9615  Â± 0.0011\n",
      "   â€¢ ROC AUC:   0.9824  Â± 0.0006\n",
      "-----------------------------------\n",
      "\n",
      "ðŸ”§ Running combination 7/12\n",
      "Params: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 10, 'min_samples_split': 5}\n",
      "-----------------------------------\n",
      "ðŸ“Œ Cross-validation metrics:\n",
      "   â€¢ Recall:    0.9265  Â± 0.0022\n",
      "   â€¢ Accuracy:  0.9812  Â± 0.0005\n",
      "   â€¢ Precision: 0.9989  Â± 0.0004\n",
      "   â€¢ F1-score:  0.9613  Â± 0.0010\n",
      "   â€¢ ROC AUC:   0.9825  Â± 0.0006\n",
      "-----------------------------------\n",
      "\n",
      "ðŸ”§ Running combination 8/12\n",
      "Params: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "-----------------------------------\n",
      "ðŸ“Œ Cross-validation metrics:\n",
      "   â€¢ Recall:    0.9265  Â± 0.0022\n",
      "   â€¢ Accuracy:  0.9812  Â± 0.0005\n",
      "   â€¢ Precision: 0.9989  Â± 0.0004\n",
      "   â€¢ F1-score:  0.9613  Â± 0.0010\n",
      "   â€¢ ROC AUC:   0.9825  Â± 0.0006\n",
      "-----------------------------------\n",
      "\n",
      "ðŸ”§ Running combination 9/12\n",
      "Params: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "-----------------------------------\n",
      "ðŸ“Œ Cross-validation metrics:\n",
      "   â€¢ Recall:    0.9544  Â± 0.0010\n",
      "   â€¢ Accuracy:  0.9875  Â± 0.0002\n"
     ]
    }
   ],
   "source": [
    "balanced_train_df = pd.read_csv(balanced_train_savepath)\n",
    "    # 3) tune decision tree with cross-validation on balanced training set and evaluate on untouched test set\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_grid = {\n",
    "    \"criterion\": [\"entropy\"],\n",
    "    \"max_depth\": [8, 12, 20],\n",
    "    \"min_samples_split\": [ 5, 10],\n",
    "    \"min_samples_leaf\": [5, 10],\n",
    "}\n",
    "\n",
    "results_dt = tune_and_evaluate(\n",
    "    balanced_train_df,\n",
    "    test_df,\n",
    "    estimator=dt,\n",
    "    param_grid=dt_grid,\n",
    "    scoring=\"recall\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_grid = {\n",
    "    \"n_neighbors\": [ 5, 7, 9 ],\n",
    "    \"weights\": [\"uniform\"],\n",
    "    \"p\": [2],     # 1 = Manhattan, 2 = Euclidean\n",
    "}\n",
    "\n",
    "results_knn = tune_and_evaluate(\n",
    "    balanced_train_df,\n",
    "    test_df,\n",
    "    estimator=knn,\n",
    "    param_grid=knn_grid,\n",
    "    scoring=\"recall\",   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_grid = {\n",
    "    \"n_estimators\": [100, 300],\n",
    "    \"max_depth\": [10, 20, 30],\n",
    "    \"min_samples_split\": [ 5, 10],\n",
    "    \"min_samples_leaf\": [5, 10],\n",
    "    \"class_weight\": [None],\n",
    "}\n",
    "\n",
    "results_rf = tune_and_evaluate(\n",
    "    balanced_train_df,\n",
    "    test_df,\n",
    "    estimator=rf,\n",
    "    param_grid=rf_grid,\n",
    "    scoring=\"recall\",   # best for imbalanced classification\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
