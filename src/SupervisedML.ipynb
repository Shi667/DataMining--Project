{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0c985f",
   "metadata": {},
   "source": [
    "## Displaying Features in `merged.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf5367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts.data_split.stratifiedSplit import stratified_split\n",
    "from scripts.TreatImbalance.BalancingTrainingData import hybrid_balance\n",
    "from scripts.Training.TrainEvaluate import train_and_evaluate \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/preprocessed/preprocessed_reduced_data.csv\"\n",
    "\n",
    "target_col = \"fire\"\n",
    "test_size = 0.2\n",
    "desired_minority_prop = (\n",
    "        0.30  # user-chosen: 0.30 means 30% minority in balanced training set\n",
    "    )\n",
    "balanced_train_savepath = \"../data/learningTestData/balanced_train.csv\"\n",
    "\n",
    "\n",
    "data_df = pd.read_csv(data_path)\n",
    "print(\"Loaded dataset with shape:\", data_df.shape)\n",
    "if target_col not in data_df.columns:\n",
    "        raise ValueError(\n",
    "            f\"Target column '{target_col}' not found in CSV columns: {data_df.columns.tolist()}\"\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = stratified_split(\n",
    "        data_df, target_col=target_col, test_size=test_size, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f12b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train_df = hybrid_balance(\n",
    "        train_df,\n",
    "        target_col=target_col,\n",
    "        minority_target=1,\n",
    "        desired_minority_prop=desired_minority_prop,\n",
    "        random_state=42,\n",
    "        save_path=balanced_train_savepath,\n",
    "        verbose=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e8540",
   "metadata": {},
   "source": [
    "## Building KNN Tree From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f41f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Try GPU ----------------------------------------------------------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "class MyKNNClassifier:\n",
    "    def __init__(self, n_neighbors=5, n_jobs=1):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_jobs = n_jobs\n",
    "        self.gpu = GPU_AVAILABLE    # auto-detect\n",
    "\n",
    "    # --- SKLEARN API ---\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"n_neighbors\": self.n_neighbors, \"n_jobs\": self.n_jobs}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for k, v in params.items():\n",
    "            setattr(self, k, v)\n",
    "        return self\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Distance (GPU or CPU)\n",
    "    # -----------------------------------------------------------\n",
    "    def _euclidean_gpu(self, X_train, x):\n",
    "        return cp.sqrt(cp.sum((X_train - x) ** 2, axis=1))\n",
    "\n",
    "    def _euclidean_cpu(self, X_train, x):\n",
    "        return np.sqrt(np.sum((X_train - x) ** 2, axis=1))\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Fit\n",
    "    # -----------------------------------------------------------\n",
    "    def fit(self, X, y):\n",
    "        if self.gpu:\n",
    "            self.X_train = cp.asarray(X, dtype=cp.float32)\n",
    "            self.y_train = cp.asarray(y)\n",
    "            self.classes_ = cp.unique(self.y_train)\n",
    "        else:\n",
    "            self.X_train = np.asarray(X, dtype=float)\n",
    "            self.y_train = np.asarray(y)\n",
    "            self.classes_ = np.unique(self.y_train)\n",
    "\n",
    "        return self\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Predict ONE sample (CPU mode)\n",
    "    # -----------------------------------------------------------\n",
    "    def _predict_one_cpu(self, x):\n",
    "        dists = self._euclidean_cpu(self.X_train, x)\n",
    "        idx = np.argpartition(dists, self.n_neighbors)[:self.n_neighbors]\n",
    "        k_labels = self.y_train[idx]\n",
    "        return np.bincount(k_labels, minlength=len(self.classes_)).argmax()\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Predict ONE sample (GPU mode)\n",
    "    # -----------------------------------------------------------\n",
    "    def _predict_one_gpu(self, x):\n",
    "        dists = self._euclidean_gpu(self.X_train, x)\n",
    "        idx = cp.argpartition(dists, self.n_neighbors)[:self.n_neighbors]\n",
    "        k_labels = self.y_train[idx]\n",
    "        pred = cp.bincount(k_labels, minlength=len(self.classes_)).argmax()\n",
    "        return int(pred.get())\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Predict\n",
    "    # -----------------------------------------------------------\n",
    "    def predict(self, X):\n",
    "        if self.gpu:\n",
    "            X = cp.asarray(X, dtype=cp.float32)\n",
    "            return np.array([self._predict_one_gpu(X[i]) for i in range(X.shape[0])])\n",
    "\n",
    "        # CPU mode ------------------------------\n",
    "        X = np.asarray(X, dtype=float)\n",
    "\n",
    "        if self.n_jobs == 1:\n",
    "            return np.array([self._predict_one_cpu(x) for x in X])\n",
    "\n",
    "        return np.array(\n",
    "            Parallel(n_jobs=self.n_jobs)(\n",
    "                delayed(self._predict_one_cpu)(x) for x in X\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Predict proba\n",
    "    # -----------------------------------------------------------\n",
    "    def predict_proba(self, X):\n",
    "        if self.gpu:\n",
    "            X = cp.asarray(X, dtype=cp.float32)\n",
    "            proba_list = []\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "                x = X[i]\n",
    "                dists = self._euclidean_gpu(self.X_train, x)\n",
    "                idx = cp.argpartition(dists, self.n_neighbors)[:self.n_neighbors]\n",
    "                k_labels = self.y_train[idx]\n",
    "                counts = cp.bincount(k_labels, minlength=len(self.classes_))\n",
    "                proba_list.append((counts / self.n_neighbors).get())\n",
    "\n",
    "            return np.array(proba_list)\n",
    "\n",
    "        # CPU mode\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        proba = np.zeros((X.shape[0], len(self.classes_)))\n",
    "\n",
    "        for i, x in enumerate(X):\n",
    "            dists = self._euclidean_cpu(self.X_train, x)\n",
    "            idx = np.argpartition(dists, self.n_neighbors)[:self.n_neighbors]\n",
    "            k_labels = self.y_train[idx]\n",
    "            counts = np.bincount(k_labels, minlength=len(self.classes_))\n",
    "            proba[i] = counts / self.n_neighbors\n",
    "\n",
    "        return proba\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Decision function\n",
    "    # -----------------------------------------------------------\n",
    "    def decision_function(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        if proba.shape[1] == 1:\n",
    "            return proba[:, 0]\n",
    "        return proba[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc208ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_neighbors\": 5,\n",
    "    \"n_jobs\" : -1 , \n",
    "}\n",
    "results_dt = train_and_evaluate(\n",
    "    balanced_train_df,\n",
    "    test_df,\n",
    "    estimator=MyKNNClassifier(),\n",
    "    algo_name = \"MyKNnClassifier\",\n",
    "    params = params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa199df",
   "metadata": {},
   "source": [
    "## Building Decision Tree From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73aa27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    class Node:\n",
    "        def __init__(self, feature=None, threshold=None, left=None, right=None, value=None, counts=None):\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.value = value      # predicted class\n",
    "            self.counts = counts    # class distribution in leaf\n",
    "\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "    # ============================================================\n",
    "    # Sklearn compatibility\n",
    "    # ============================================================\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            \"max_depth\": self.max_depth,\n",
    "            \"min_samples_split\": self.min_samples_split,\n",
    "            \"min_samples_leaf\": self.min_samples_leaf,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for k, v in params.items():\n",
    "            setattr(self, k, v)\n",
    "        return self\n",
    "\n",
    "    # ============================================================\n",
    "    # Internal helpers\n",
    "    # ============================================================\n",
    "    def entropy(self, counts):\n",
    "        total = counts.sum()\n",
    "        if total == 0:\n",
    "            return 0\n",
    "        p = counts / total\n",
    "        return -(p * np.log2(p + 1e-9)).sum()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        idx = np.arange(len(y))\n",
    "        self.tree_ = self._build(idx, depth=0)\n",
    "        return self\n",
    "\n",
    "    def _build(self, idx, depth):\n",
    "        y = self.y[idx]\n",
    "        counts = np.bincount(y, minlength=self.n_classes_)\n",
    "\n",
    "        # stopping conditions\n",
    "        if (\n",
    "            len(idx) < self.min_samples_split or\n",
    "            (self.max_depth is not None and depth >= self.max_depth)\n",
    "        ):\n",
    "            return self.Node(value=np.argmax(counts), counts=counts)\n",
    "\n",
    "        n_features = self.X.shape[1]\n",
    "        parent_entropy = self.entropy(counts)\n",
    "\n",
    "        best_gain = 0\n",
    "        best_feat = None\n",
    "        best_thresh = None\n",
    "        best_left = None\n",
    "        best_right = None\n",
    "\n",
    "        for f in range(n_features):\n",
    "            col = self.X[idx, f]\n",
    "            order = np.argsort(col)\n",
    "            sorted_idx = idx[order]\n",
    "            sorted_y = self.y[sorted_idx]\n",
    "            sorted_col = col[order]\n",
    "\n",
    "            left_counts = np.zeros(self.n_classes_, dtype=np.int32)\n",
    "            right_counts = np.bincount(sorted_y, minlength=self.n_classes_)\n",
    "\n",
    "            for i in range(len(idx) - 1):\n",
    "                c = sorted_y[i]\n",
    "                left_counts[c] += 1\n",
    "                right_counts[c] -= 1\n",
    "\n",
    "                if sorted_col[i] == sorted_col[i+1]:\n",
    "                    continue\n",
    "\n",
    "                left_n = i + 1\n",
    "                right_n = len(idx) - left_n\n",
    "\n",
    "                if left_n < self.min_samples_leaf or right_n < self.min_samples_leaf:\n",
    "                    continue\n",
    "\n",
    "                thresh = (sorted_col[i] + sorted_col[i+1]) / 2\n",
    "\n",
    "                gain = parent_entropy - (\n",
    "                    (left_n / len(idx)) * self.entropy(left_counts)\n",
    "                    + (right_n / len(idx)) * self.entropy(right_counts)\n",
    "                )\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feat = f\n",
    "                    best_thresh = thresh\n",
    "                    best_left = sorted_idx[:left_n]\n",
    "                    best_right = sorted_idx[left_n:]\n",
    "\n",
    "        if best_gain == 0:\n",
    "            return self.Node(value=np.argmax(counts), counts=counts)\n",
    "\n",
    "        left_node = self._build(best_left, depth+1)\n",
    "        right_node = self._build(best_right, depth+1)\n",
    "        return self.Node(feature=best_feat, threshold=best_thresh,\n",
    "                         left=left_node, right=right_node, counts=counts)\n",
    "\n",
    "    def _predict_node(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._predict_node(x, node.left)\n",
    "        return self._predict_node(x, node.right)\n",
    "\n",
    "    # ============================================================\n",
    "    # Required sklearn prediction API\n",
    "    # ============================================================\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        preds = []\n",
    "        for x in X:\n",
    "            node = self._predict_node(x, self.tree_)\n",
    "            preds.append(node.value)\n",
    "        return np.array(preds)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Return class probabilities using the leaf distribution.\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        proba = []\n",
    "        for x in X:\n",
    "            node = self._predict_node(x, self.tree_)\n",
    "            counts = node.counts\n",
    "            p = counts / counts.sum()\n",
    "            proba.append(p)\n",
    "        return np.array(proba)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Return raw scores (class counts before normalization).\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        scores = []\n",
    "        for x in X:\n",
    "            node = self._predict_node(x, self.tree_)\n",
    "            scores.append(node.counts)\n",
    "        return np.array(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": 20,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"min_samples_leaf\": 5,\n",
    "    \"criterion\": \"entropy\",\n",
    "\n",
    "}\n",
    "\n",
    "results_dt = train_and_evaluate(\n",
    "    balanced_train_df,\n",
    "    test_df,\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    algo_name = \"DecisionTreeClassifier_skLearn\",\n",
    "    params = params,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cddd2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": 20,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"min_samples_leaf\": 5,\n",
    "    \"criterion\": \"entropy\",\n",
    "\n",
    "}\n",
    "\n",
    "results_dt = train_and_evaluate(\n",
    "    balanced_train_df,\n",
    "    test_df,\n",
    "    estimator=MyDecisionTreeClassifier(),\n",
    "    algo_name = \"MyDecisionTreeClassifier\",\n",
    "    params = params,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
