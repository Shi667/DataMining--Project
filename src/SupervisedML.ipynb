{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0c985f",
   "metadata": {},
   "source": [
    "## Displaying Features in `merged.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9053d98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features/Columns in merge.csv:\n",
      "['elevation', 'GRIDCODE', 'spring_prec', 'summer_prec', 'autumn_prec', 'winter_prec', 'summer_tmax', 'autumn_tmax', 'spring_tmax', 'winter_tmax', 'winter_tmin', 'summer_tmin', 'ORG_CARBON', 'CEC_CLAY', 'GYPSUM', 'BSAT', 'PH_WATER', 'SAND', 'SILT', 'BULK', 'TCARBON_EQ', 'TOTAL_N', 'COARSE', 'CEC_SOIL', 'CN_RATIO', 'ESP', 'ELEC_COND', 'TEX_5', 'TEX_9', 'ALUM_SAT', 'fire']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the merged cleaned dataset\n",
    "df = pd.read_csv('../data/Merged/reduced_North_data.csv')\n",
    "\n",
    "# Display feature names\n",
    "print(\"Features/Columns in merge.csv:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe1a57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 99283, Test samples: 24821\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/Merged/reduced_North_data.csv')\n",
    "\n",
    "# Features (all except 'fire'), Target ('fire')\n",
    "X = df.drop('fire', axis=1)\n",
    "y = df['fire']\n",
    "\n",
    "# Split into training and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Confirm shapes\n",
    "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa199df",
   "metadata": {},
   "source": [
    "## Building K-Nearest Neighbors (KNN) From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbcb8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "class MyKNNClassifier:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        y_pred = []\n",
    "        for x in X:\n",
    "            distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_neighbor_labels = self.y_train[k_indices]\n",
    "            most_common = Counter(k_neighbor_labels).most_common(1)[0][0]\n",
    "            y_pred.append(most_common)\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a4a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = MyKNNClassifier(k=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b43a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9981064421256194\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     24772\n",
      "           1       0.75      0.06      0.11        49\n",
      "\n",
      "    accuracy                           1.00     24821\n",
      "   macro avg       0.87      0.53      0.56     24821\n",
      "weighted avg       1.00      1.00      1.00     24821\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24771     1]\n",
      " [   46     3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Most likely, knn_preds is a simple array of scalars\n",
    "y_pred = [p for p in knn_preds]  # OR, just: y_pred = knn_preds if it's already a list-like\n",
    "\n",
    "# Now evaluate as before\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c89f1607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9981064421256194\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     24772\n",
      "           1       0.75      0.06      0.11        49\n",
      "\n",
      "    accuracy                           1.00     24821\n",
      "   macro avg       0.87      0.53      0.56     24821\n",
      "weighted avg       1.00      1.00      1.00     24821\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24771     1]\n",
      " [   46     3]]\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distances(X1, X2):\n",
    "    # Renvoie la matrice des distances euclidiennes (vectorisé, GPU)\n",
    "    # X1: (batch_size, n_features), X2: (n_train, n_features)\n",
    "    # Résultat: (batch_size, n_train)\n",
    "    return cp.sqrt(cp.sum((X1[:, cp.newaxis, :] - X2[cp.newaxis, :, :]) ** 2, axis=2))\n",
    "\n",
    "class MyKNNClassifierGPU:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "    def fit(self, X, y):\n",
    "        # X et y doivent être des np.arrays float32/int32\n",
    "        self.X_train = cp.array(X.astype(np.float32))\n",
    "        self.y_train = cp.array(y.astype(np.int32))\n",
    "    def predict(self, X, batch_size=100):\n",
    "        X = cp.array(X.astype(np.float32))\n",
    "        N = X.shape[0]\n",
    "        y_pred = []\n",
    "        for start in range(0, N, batch_size):\n",
    "            end = min(start + batch_size, N)\n",
    "            X_batch = X[start:end]\n",
    "            distances = euclidean_distances(X_batch, self.X_train)  # (batch, n_train)\n",
    "            neighbors_idx = cp.argpartition(distances, self.k, axis=1)[:, :self.k]\n",
    "            # Pour chaque ligne du batch, vote majoritaire\n",
    "            for i, idxs in enumerate(neighbors_idx):\n",
    "                k_labels = cp.asnumpy(self.y_train[idxs])\n",
    "                most_common = Counter(k_labels).most_common(1)[0][0]\n",
    "                y_pred.append(most_common)\n",
    "        return np.array(y_pred)   # pour sklearn metrics\n",
    "\n",
    "# --- Préparation des données ---\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/Merged/reduced_North_data.csv')\n",
    "X = df.drop('fire', axis=1).values.astype(np.float32)\n",
    "y = df['fire'].astype(np.int32).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Entraînement et prédiction ---\n",
    "knn_gpu = MyKNNClassifierGPU(k=5)\n",
    "knn_gpu.fit(X_train, y_train)\n",
    "y_pred = knn_gpu.predict(X_test, batch_size=100)   # ajuste batch_size selon ta RAM GPU\n",
    "\n",
    "# --- Évaluation des performances ---\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae6f28",
   "metadata": {},
   "source": [
    "## Building Decision Tree (DT) From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5721663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy (hybride CuPy): 0.998751057572217\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     24772\n",
      "           1       0.76      0.53      0.63        49\n",
      "\n",
      "    accuracy                           1.00     24821\n",
      "   macro avg       0.88      0.77      0.81     24821\n",
      "weighted avg       1.00      1.00      1.00     24821\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[24764     8]\n",
      " [   23    26]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class SimpleDecisionTreeClassifierCuPy:\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "\n",
    "    def _gini(self, y):\n",
    "        # Gini sur GPU si tableau long, sinon CPU\n",
    "        if len(y) > 500:\n",
    "            y_gpu = cp.array(y)\n",
    "            classes = cp.unique(y_gpu)\n",
    "            m = y_gpu.size\n",
    "            probs = cp.array([cp.sum(y_gpu == c) / m for c in classes])\n",
    "            return float(1.0 - cp.sum(probs ** 2))\n",
    "        else:\n",
    "            m = len(y)\n",
    "            return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in np.unique(y))\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        # Utilise np ici car souvent peu de classes\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = DecisionTreeNode(\n",
    "            gini=self._gini(y),\n",
    "            num_samples=len(y),\n",
    "            num_samples_per_class=num_samples_per_class,\n",
    "            predicted_class=predicted_class,\n",
    "        )\n",
    "\n",
    "        if node.gini == 0:  # pure node\n",
    "            return node\n",
    "\n",
    "        idx, thr = self._best_split(X, y)\n",
    "        if idx is None:\n",
    "            return node\n",
    "\n",
    "        indices_left = X[:, idx] < thr\n",
    "        X_left, y_left = X[indices_left], y[indices_left]\n",
    "        X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "        node.feature_index = idx\n",
    "        node.threshold = thr\n",
    "        node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "        node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "        best_gini = 1.0\n",
    "        best_idx, best_thr = None, None\n",
    "        for idx in range(n):\n",
    "            # Accélère le tri sur GPU si possible\n",
    "            if m > 2000:\n",
    "                sorted_idx = cp.asnumpy(cp.argsort(cp.array(X[:, idx])))\n",
    "            else:\n",
    "                sorted_idx = np.argsort(X[:, idx])\n",
    "            thresholds = X[sorted_idx, idx]\n",
    "            classes = y[sorted_idx]\n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                if i == 0 or m - i == 0:\n",
    "                    continue\n",
    "                # calcule gini_left/gini_right par GPU si assez de données\n",
    "                if i > 500 and m-i > 500:\n",
    "                    left_arr = cp.array(num_left)\n",
    "                    right_arr = cp.array(num_right)\n",
    "                    gini_left = 1.0 - float(cp.sum((left_arr / i) ** 2))\n",
    "                    gini_right = 1.0 - float(cp.sum((right_arr / (m - i)) ** 2))\n",
    "                else:\n",
    "                    gini_left = 1.0 - sum((num_left[x] / i) ** 2 for x in range(self.n_classes_))\n",
    "                    gini_right = 1.0 - sum((num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_))\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree_\n",
    "        while node.left is not None:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class\n",
    "\n",
    "# --- Utilisation ---\n",
    "# les X et y doivent être des np.array (pas cupy) en entrée\n",
    "# car la logique d’arbre est sur CPU\n",
    "\n",
    "tree = SimpleDecisionTreeClassifierCuPy()\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(\"Decision Tree Accuracy (hybride CuPy):\", accuracy_score(y_test, y_pred_tree))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_tree))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52303850",
   "metadata": {},
   "source": [
    "## Building Random Forest (RF) From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea247994",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Utilisation sur tes données\u001b[39;00m\n\u001b[0;32m     24\u001b[0m forest \u001b[38;5;241m=\u001b[39m SimpleRandomForestClassifierCuPy(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mforest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m y_pred_forest \u001b[38;5;241m=\u001b[39m forest\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix\n",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mSimpleRandomForestClassifierCuPy.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     13\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(n_samples, n_sub, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m tree \u001b[38;5;241m=\u001b[39m SimpleDecisionTreeClassifierCuPy()  \u001b[38;5;66;03m# Cupy optimized\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees\u001b[38;5;241m.\u001b[39mappend(tree)\n",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m, in \u001b[0;36mSimpleDecisionTreeClassifierCuPy.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 56\u001b[0m, in \u001b[0;36mSimpleDecisionTreeClassifierCuPy._grow_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     54\u001b[0m node\u001b[38;5;241m.\u001b[39mfeature_index \u001b[38;5;241m=\u001b[39m idx\n\u001b[0;32m     55\u001b[0m node\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m thr\n\u001b[1;32m---> 56\u001b[0m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m node\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grow_tree(X_right, y_right, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "Cell \u001b[1;32mIn[6], line 57\u001b[0m, in \u001b[0;36mSimpleDecisionTreeClassifierCuPy._grow_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     55\u001b[0m node\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m thr\n\u001b[0;32m     56\u001b[0m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grow_tree(X_left, y_left, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m node\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "Cell \u001b[1;32mIn[6], line 57\u001b[0m, in \u001b[0;36mSimpleDecisionTreeClassifierCuPy._grow_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     55\u001b[0m node\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m thr\n\u001b[0;32m     56\u001b[0m node\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grow_tree(X_left, y_left, depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m node\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grow_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "Cell \u001b[1;32mIn[6], line 47\u001b[0m, in \u001b[0;36mSimpleDecisionTreeClassifierCuPy._grow_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mgini \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# pure node\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n\u001b[1;32m---> 47\u001b[0m idx, thr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_best_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "Cell \u001b[1;32mIn[6], line 88\u001b[0m, in \u001b[0;36mSimpleDecisionTreeClassifierCuPy._best_split\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m     left_arr \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39marray(num_left)\n\u001b[0;32m     87\u001b[0m     right_arr \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39marray(num_right)\n\u001b[1;32m---> 88\u001b[0m     gini_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(cp\u001b[38;5;241m.\u001b[39msum(\u001b[43m(\u001b[49m\u001b[43mleft_arr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m))\n\u001b[0;32m     89\u001b[0m     gini_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(cp\u001b[38;5;241m.\u001b[39msum((right_arr \u001b[38;5;241m/\u001b[39m (m \u001b[38;5;241m-\u001b[39m i)) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mcupy/_core/core.pyx:1448\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__pow__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy/_core/core.pyx:1799\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__array_ufunc__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy/_core/_kernel.pyx:1333\u001b[0m, in \u001b[0;36mcupy._core._kernel.ufunc.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy/_core/_kernel.pyx:1593\u001b[0m, in \u001b[0;36mcupy._core._kernel._Ops.guess_routine\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy/_core/_kernel.pyx:1116\u001b[0m, in \u001b[0;36mcupy._core._kernel._min_scalar_type\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\IFTA\\miniconda3\\envs\\projetDM\\lib\\site-packages\\numpy\\_core\\multiarray.py:642\u001b[0m, in \u001b[0;36mmin_scalar_type\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;124;03m    can_cast(from_, to, casting='safe')\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (from_,)\n\u001b[1;32m--> 642\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mmin_scalar_type)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmin_scalar_type\u001b[39m(a):\n\u001b[0;32m    644\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;124;03m    min_scalar_type(a, /)\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    685\u001b[0m \n\u001b[0;32m    686\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SimpleRandomForestClassifierCuPy:\n",
    "    def __init__(self, n_estimators=10, max_samples=0.7):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        n_sub = int(self.max_samples * n_samples)\n",
    "        for _ in range(self.n_estimators):\n",
    "            indices = np.random.choice(n_samples, n_sub, replace=True)\n",
    "            tree = SimpleDecisionTreeClassifierCuPy()  # Cupy optimized\n",
    "            tree.fit(X[indices], y[indices])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Prédictions de chaque arbre (majorité en colonne)\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.array([np.bincount(tree_preds[:, i]).argmax() for i in range(X.shape[0])])\n",
    "\n",
    "# Utilisation sur tes données\n",
    "forest = SimpleRandomForestClassifierCuPy(n_estimators=10, max_samples=0.7)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred_forest = forest.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "print(\"Random Forest Accuracy (Cupy optimisé):\", accuracy_score(y_test, y_pred_forest))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_forest))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_forest))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projetDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
