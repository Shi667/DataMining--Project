{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0c985f",
   "metadata": {},
   "source": [
    "## Displaying Features in `merged.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "DATA_PATH = '../data/preprocessed/preprocessed_reduced_data.csv'\n",
    "# Load the merged cleaned dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Display feature names\n",
    "print(\"Features/Columns in preprocessed_reduced_data.csv:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe1a57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Using stratified split â†’ class ratios preserved.\n",
      "\n",
      "=== Testing Resampling Methods ===\n",
      "\n",
      "NONE:\n",
      "  recall     = 0.9232\n",
      "  precision  = 0.9964\n",
      "  f1         = 0.9584\n",
      "  roc_auc    = 0.9798\n",
      "\n",
      "UNDERSAMPLE:\n",
      "  recall     = 0.9573\n",
      "  precision  = 0.9793\n",
      "  f1         = 0.9682\n",
      "  roc_auc    = 0.9809\n",
      "\n",
      "NEARMISS:\n",
      "  recall     = 0.9472\n",
      "  precision  = 0.9959\n",
      "  f1         = 0.9709\n",
      "  roc_auc    = 0.9828\n",
      "\n",
      "SMOTE:\n",
      "  recall     = 0.9685\n",
      "  precision  = 0.9951\n",
      "  f1         = 0.9817\n",
      "  roc_auc    = 0.9926\n",
      "\n",
      "HYBRID:\n",
      "  recall     = 0.9699\n",
      "  precision  = 0.9972\n",
      "  f1         = 0.9833\n",
      "  roc_auc    = 0.9924\n",
      "\n",
      "ðŸ”¥ BEST METHOD (by recall): HYBRID\n",
      "ðŸ’¾ Saved balanced train set to: ../data/preprocessed/preprocessed_reduced_balanced_data.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('hybrid',\n",
       " {'none': {'recall': np.float64(0.92320266153764),\n",
       "   'precision': np.float64(0.9963862816567582),\n",
       "   'f1': np.float64(0.9583963528286937),\n",
       "   'roc_auc': np.float64(0.979806545307965),\n",
       "   'degenerate': False},\n",
       "  'undersample': {'recall': np.float64(0.9573236563604871),\n",
       "   'precision': np.float64(0.9792576059812331),\n",
       "   'f1': np.float64(0.9681647196072879),\n",
       "   'roc_auc': np.float64(0.9808534924721138),\n",
       "   'degenerate': False},\n",
       "  'nearmiss': {'recall': np.float64(0.9471943220810474),\n",
       "   'precision': np.float64(0.9958639232348063),\n",
       "   'f1': np.float64(0.9709177486479322),\n",
       "   'roc_auc': np.float64(0.9828378762983299),\n",
       "   'degenerate': False},\n",
       "  'smote': {'recall': np.float64(0.9685372113869573),\n",
       "   'precision': np.float64(0.9951397882313442),\n",
       "   'f1': np.float64(0.9816578622878412),\n",
       "   'roc_auc': np.float64(0.9926088540822965),\n",
       "   'degenerate': False},\n",
       "  'hybrid': {'recall': np.float64(0.969863500556407),\n",
       "   'precision': np.float64(0.9971950428511193),\n",
       "   'f1': np.float64(0.9833391738238509),\n",
       "   'roc_auc': np.float64(0.9923712038989377),\n",
       "   'degenerate': False}},\n",
       "          spring_prec  autumn_prec  summer_prec  winter_prec  elevation  \\\n",
       " 0           0.458018    -0.104224     0.341153    -0.296158   1.523669   \n",
       " 1           0.016818    -0.443741    -0.530938    -0.489726   1.064514   \n",
       " 2          -0.022859    -0.660329     0.824688    -0.262606   0.354218   \n",
       " 3          -0.965566    -1.054481    -0.202824    -0.940525  -0.508284   \n",
       " 4          -0.440253    -0.777404    -0.340977    -0.405416  -1.462109   \n",
       " ...              ...          ...          ...          ...        ...   \n",
       " 1073975     0.925290    -1.269675     0.999845     1.698888  -1.628812   \n",
       " 1073976     0.223461     1.166498    -1.506642     0.132354  -1.281394   \n",
       " 1073977     0.959525    -1.421315     0.030309     2.053332  -0.586541   \n",
       " 1073978     3.903504     1.882144     3.130115    -0.046670   1.155008   \n",
       " 1073979     2.725912     4.609985    -1.161260     2.121296  -1.160248   \n",
       " \n",
       "          autumn_tmax  autumn_tmin  spring_tmax  summer_tmax  winter_tmin  ...  \\\n",
       " 0          -0.645629    -0.587157    -0.810936    -0.924249    -1.060445  ...   \n",
       " 1          -0.961286    -0.587157    -0.495659    -1.249098    -0.820900  ...   \n",
       " 2          -0.435191    -0.691601    -0.285475     0.266866    -0.461583  ...   \n",
       " 3           1.143093     0.666175     1.711273     1.891114     0.017507  ...   \n",
       " 4           0.616999     0.352842     0.975629    -0.382833     1.095458  ...   \n",
       " ...              ...          ...          ...          ...          ...  ...   \n",
       " 1073975     1.338501     1.352526     0.029801    -1.403791     1.146792  ...   \n",
       " 1073976     0.511780    -0.220219    -0.021354     0.969274    -0.222038  ...   \n",
       " 1073977     0.722217     1.292841    -0.180383    -1.249098     0.855913  ...   \n",
       " 1073978    -1.908256    -1.213823    -1.336396    -1.357381    -0.701128  ...   \n",
       " 1073979    -0.224753     0.352842    -0.810936    -0.599399     0.137279  ...   \n",
       " \n",
       "            COARSE      BSAT    GYPSUM  ALUM_SAT  ELEC_COND  TEXTURE_USDA_5.0  \\\n",
       " 0       -1.090224  0.588426 -0.285102 -0.132202   0.151824             False   \n",
       " 1       -0.966601  0.799679 -0.086719 -0.132202  -0.210288             False   \n",
       " 2       -0.842978  0.729261 -0.099118 -0.132202  -0.210288              True   \n",
       " 3       -0.966601  0.799679  4.463686 -0.132202   0.151824             False   \n",
       " 4       -0.101241 -0.749506 -0.347097 -0.132202  -0.210288              True   \n",
       " ...           ...       ...       ...       ...        ...               ...   \n",
       " 1073975 -0.101241 -0.749506 -0.347097 -0.132202  -0.210288              True   \n",
       " 1073976  1.258610 -1.735351 -0.322299 -0.132202  -0.210288             False   \n",
       " 1073977 -0.842978 -0.467836 -0.161113 -0.132202  -0.210288              True   \n",
       " 1073978  1.258610 -1.735351 -0.322299 -0.132202  -0.210288             False   \n",
       " 1073979  1.258610 -1.735351 -0.322299 -0.132202  -0.210288             False   \n",
       " \n",
       "          TEXTURE_USDA_11.0  TEXTURE_USDA_9.0  TEXTURE_USDA_10.0  fire  \n",
       " 0                    False              True              False     0  \n",
       " 1                    False              True              False     0  \n",
       " 2                    False             False              False     0  \n",
       " 3                    False              True              False     0  \n",
       " 4                    False             False              False     0  \n",
       " ...                    ...               ...                ...   ...  \n",
       " 1073975              False             False              False     1  \n",
       " 1073976              False              True              False     1  \n",
       " 1073977              False             False              False     1  \n",
       " 1073978              False              True              False     1  \n",
       " 1073979              False              True              False     1  \n",
       " \n",
       " [1073980 rows x 36 columns],\n",
       "         spring_prec  autumn_prec  summer_prec  winter_prec  elevation  \\\n",
       " 626902     0.286616     1.493846     0.626093     2.424983   0.262894   \n",
       " 262141     2.268842     1.105548     0.047578    -0.447571   1.559184   \n",
       " 242997    -0.433905    -0.709110     0.177096    -0.548227   1.439955   \n",
       " 8873      -0.768772    -0.086663    -1.627526    -0.770185  -1.510308   \n",
       " 412459    -0.827493    -0.863259    -0.600014    -0.728891  -0.305342   \n",
       " ...             ...          ...          ...          ...        ...   \n",
       " 422554    -0.651331    -0.691549     0.151192    -0.580918  -0.312952   \n",
       " 10158     -1.040158    -1.122774    -0.781340    -0.939665  -0.701078   \n",
       " 99489     -0.667201    -0.428131     1.843565    -0.695339   1.445029   \n",
       " 285659    -0.540237     0.481149    -1.126722    -0.568874  -1.388543   \n",
       " 376783     0.886521     0.065534    -0.539572    -0.390791   1.445029   \n",
       " \n",
       "         autumn_tmax  autumn_tmin  spring_tmax  summer_tmax  winter_tmin  ...  \\\n",
       " 626902    -0.750848    -0.273824    -1.336396    -1.140815    -0.102266  ...   \n",
       " 262141    -1.487380    -1.422711    -1.126212    -0.924249    -2.258169  ...   \n",
       " 242997    -0.856067    -1.004934    -0.705844    -0.274550    -1.060445  ...   \n",
       " 8873       2.300502     1.815063     1.921457     1.024848     0.975686  ...   \n",
       " 412459     0.616999     0.666175     0.870537     1.457981     0.376824  ...   \n",
       " ...             ...          ...          ...          ...          ...  ...   \n",
       " 422554     0.511780     0.248398     0.660353     1.024848     0.017507  ...   \n",
       " 10158      1.458750     0.979508     2.131641     2.215963     0.017507  ...   \n",
       " 99489     -0.961286    -1.318267    -0.600751    -0.057983    -1.539535  ...   \n",
       " 285659     1.563969     1.501730     1.185813     0.808282     1.335003  ...   \n",
       " 376783    -0.329972    -0.587157    -0.495659    -0.166266    -0.940673  ...   \n",
       " \n",
       "           COARSE      BSAT    GYPSUM  ALUM_SAT  ELEC_COND  TEXTURE_USDA_5.0  \\\n",
       " 626902  1.258610 -1.735351 -0.322299 -0.132202  -0.210288             False   \n",
       " 262141 -0.966601  0.799679 -0.086719 -0.132202  -0.210288             False   \n",
       " 242997  0.516873  0.588426  0.000073 -0.132202  -0.210288             False   \n",
       " 8873    4.225558  0.306756 -0.322299 -0.132202  -0.210288             False   \n",
       " 412459  0.022382  0.799679 -0.334698 -0.132202  -0.210288             False   \n",
       " ...          ...       ...       ...       ...        ...               ...   \n",
       " 422554 -0.966601  0.518009 -0.347097 -0.132202  -0.210288             False   \n",
       " 10158   0.022382  0.799679 -0.334698 -0.132202  -0.210288             False   \n",
       " 99489   0.022382  0.799679 -0.334698 -0.132202  -0.210288             False   \n",
       " 285659 -0.348487  0.799679 -0.334698 -0.132202  -0.210288             False   \n",
       " 376783  0.022382  0.799679 -0.334698 -0.132202  -0.210288             False   \n",
       " \n",
       "         TEXTURE_USDA_11.0  TEXTURE_USDA_9.0  TEXTURE_USDA_10.0  fire  \n",
       " 626902              False              True              False     0  \n",
       " 262141              False              True              False     1  \n",
       " 242997              False              True              False     0  \n",
       " 8873                False              True              False     0  \n",
       " 412459              False              True              False     0  \n",
       " ...                   ...               ...                ...   ...  \n",
       " 422554              False              True              False     0  \n",
       " 10158               False              True              False     0  \n",
       " 99489               False              True              False     0  \n",
       " 285659               True             False              False     0  \n",
       " 376783              False              True              False     0  \n",
       " \n",
       " [147097 rows x 36 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, f1_score, recall_score, precision_score, roc_auc_score\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# AVAILABLE SAMPLERS\n",
    "# ============================================================\n",
    "def apply_resampling(method, X, y):\n",
    "    if method == \"none\":\n",
    "        return X, y\n",
    "    if method == \"undersample\":\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        return rus.fit_resample(X, y)\n",
    "    if method == \"nearmiss\":\n",
    "        nm = NearMiss(version=1)\n",
    "        return nm.fit_resample(X, y)\n",
    "    if method == \"smote\":\n",
    "        sm = SMOTE(k_neighbors=3, random_state=42)\n",
    "        return sm.fit_resample(X, y)\n",
    "    if method == \"hybrid\":\n",
    "        smt = SMOTETomek(random_state=42)\n",
    "        return smt.fit_resample(X, y)\n",
    "\n",
    "    raise ValueError(\"Unknown resampling method\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EVALUATE RESAMPLING WITH ALL METRICS\n",
    "# ============================================================\n",
    "def evaluate_resampling(method, X, y, cv):\n",
    "\n",
    "    X_res, y_res = apply_resampling(method, X, y)\n",
    "\n",
    "    model = DecisionTreeClassifier(\n",
    "        max_depth=20,\n",
    "        min_samples_leaf=3,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scoring = {\n",
    "        \"recall\": make_scorer(recall_score),\n",
    "        \"precision\": make_scorer(precision_score),\n",
    "        \"f1\": make_scorer(f1_score),\n",
    "        \"roc_auc\": \"roc_auc\"\n",
    "    }\n",
    "\n",
    "    scores = cross_validate(\n",
    "        model, X_res, y_res,\n",
    "        cv=cv, scoring=scoring, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Mean of each metric\n",
    "    res = {metric: scores[f\"test_{metric}\"].mean() for metric in scoring}\n",
    "\n",
    "    # Detection of degenerate model\n",
    "    if len(set(y_res)) == 1:\n",
    "        res[\"degenerate\"] = True\n",
    "    else:\n",
    "        res[\"degenerate\"] = False\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MASTER FUNCTION â€“ SELECT BEST RESAMPLING METHOD\n",
    "# ============================================================\n",
    "def choose_best_resampling(\n",
    "        csv_path,\n",
    "        target_col=\"fire\",\n",
    "        metric=\"recall\",\n",
    "        k_folds=3,\n",
    "        output_csv=\"balanced_data.csv\"\n",
    "):\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, test_size=0.2, stratify=df[target_col], random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"âœ” Using stratified split â†’ class ratios preserved.\")\n",
    "\n",
    "    X_train = train_df.drop(columns=[target_col])\n",
    "    y_train = train_df[target_col]\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    methods = [\"none\", \"undersample\", \"nearmiss\", \"smote\", \"hybrid\"]\n",
    "    results = {}\n",
    "\n",
    "    print(\"\\n=== Testing Resampling Methods ===\")\n",
    "    for m in methods:\n",
    "        metrics = evaluate_resampling(m, X_train, y_train, cv)\n",
    "        results[m] = metrics\n",
    "\n",
    "        print(f\"\\n{m.upper()}:\")\n",
    "        for k, v in metrics.items():\n",
    "            if k != \"degenerate\":\n",
    "                print(f\"  {k:10s} = {v:.4f}\")\n",
    "        if metrics[\"degenerate\"]:\n",
    "            print(\"  âš  Model predicts only one class (degenerate)\")\n",
    "\n",
    "    # Select based on recall\n",
    "    best_method = max(results, key=lambda m: results[m][\"recall\"])\n",
    "    print(\"\\nðŸ”¥ BEST METHOD (by recall):\", best_method.upper())\n",
    "\n",
    "    # Apply to full training set\n",
    "    X_res, y_res = apply_resampling(best_method, X_train, y_train)\n",
    "    balanced_df = pd.concat(\n",
    "        [pd.DataFrame(X_res), pd.DataFrame(y_res, columns=[target_col])],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    balanced_df.to_csv(output_csv, index=False)\n",
    "    print(f\"ðŸ’¾ Saved balanced train set to: {output_csv}\")\n",
    "\n",
    "    return best_method, results, balanced_df, test_df\n",
    "\n",
    "\n",
    "choose_best_resampling( csv_path=\"../data/preprocessed/preprocessed_reduced_data.csv\", \n",
    "                       target_col=\"fire\", \n",
    "                       metric=\"recall\", \n",
    "                       k_folds=3, \n",
    "                       output_csv=\"../data/preprocessed/preprocessed_reduced_balanced_data.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd4b6b67",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 59\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {m: np\u001b[38;5;241m.\u001b[39mmean(vals) \u001b[38;5;28;01mfor\u001b[39;00m m, vals \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     57\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/preprocessed/preprocessed_reduced_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbalanced_realistic_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfire\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Cell \u001b[1;32mIn[8], line 32\u001b[0m, in \u001b[0;36mbalanced_realistic_cv\u001b[1;34m(df, target_col, n_splits)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 2. Light SMOTE â†’ increase minority but not to 50/50\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[0;32m     31\u001b[0m sm \u001b[38;5;241m=\u001b[39m SMOTE(sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m X_train_bal, y_train_bal \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_rus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_rus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 3. Decision Tree with class_weight for realism\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[0;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(\n\u001b[0;32m     38\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     40\u001b[0m )\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\imblearn\\base.py:202\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\imblearn\\base.py:101\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m     98\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m     99\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_sampling_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampling_type\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    107\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    109\u001b[0m )\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\imblearn\\utils\\_validation.py:569\u001b[0m, in \u001b[0;36mcheck_sampling_strategy\u001b[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sampling_strategy \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m sampling_strategy \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    564\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_strategy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a float, it should be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the range (0, 1]. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m         )\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[0;32m    568\u001b[0m         \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m--> 569\u001b[0m             \u001b[43m_sampling_strategy_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    570\u001b[0m         )\n\u001b[0;32m    571\u001b[0m     )\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(sampling_strategy):\n\u001b[0;32m    573\u001b[0m     sampling_strategy_ \u001b[38;5;241m=\u001b[39m sampling_strategy(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\usthb\\M2\\DataMining\\projet\\DataMining--Project\\DMenv\\lib\\site-packages\\imblearn\\utils\\_validation.py:408\u001b[0m, in \u001b[0;36m_sampling_strategy_float\u001b[1;34m(sampling_strategy, y, sampling_type)\u001b[0m\n\u001b[0;32m    402\u001b[0m     sampling_strategy_ \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    403\u001b[0m         key: \u001b[38;5;28mint\u001b[39m(n_sample_majority \u001b[38;5;241m*\u001b[39m sampling_strategy \u001b[38;5;241m-\u001b[39m value)\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (key, value) \u001b[38;5;129;01min\u001b[39;00m target_stats\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m class_majority\n\u001b[0;32m    406\u001b[0m     }\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m([n_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_samples \u001b[38;5;129;01min\u001b[39;00m sampling_strategy_\u001b[38;5;241m.\u001b[39mvalues()]):\n\u001b[1;32m--> 408\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    409\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe specified ratio required to remove samples \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the minority class while trying to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerate new samples. Please increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mratio.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m         )\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder-sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    415\u001b[0m     n_sample_minority \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(target_stats\u001b[38;5;241m.\u001b[39mvalues())\n",
      "\u001b[1;31mValueError\u001b[0m: The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def balanced_realistic_cv(df, target_col=\"fire\", n_splits=5):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    metrics = {\"accuracy\": [], \"precision\": [], \"recall\": [], \"f1\": []}\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # ===================================================\n",
    "        # 1. Light undersampling â†’ keep 70% majority\n",
    "        # ===================================================\n",
    "        rus = RandomUnderSampler(sampling_strategy=0.7, random_state=42)\n",
    "        X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "        # ===================================================\n",
    "        # 2. Light SMOTE â†’ increase minority but not to 50/50\n",
    "        # ===================================================\n",
    "        sm = SMOTE(sampling_strategy=0.4, random_state=42)\n",
    "        X_train_bal, y_train_bal = sm.fit_resample(X_train_rus, y_train_rus)\n",
    "\n",
    "        # ===================================================\n",
    "        # 3. Decision Tree with class_weight for realism\n",
    "        # ===================================================\n",
    "        model = DecisionTreeClassifier(\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "        # ===================================================\n",
    "        # 4. Test only on real data\n",
    "        # ===================================================\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Save metrics\n",
    "        metrics[\"accuracy\"].append(accuracy_score(y_test, y_pred))\n",
    "        metrics[\"precision\"].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        metrics[\"recall\"].append(recall_score(y_test, y_pred, zero_division=0))\n",
    "        metrics[\"f1\"].append(f1_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    return {m: np.mean(vals) for m, vals in metrics.items()}\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/preprocessed/preprocessed_reduced_data.csv\")\n",
    "\n",
    "results = balanced_realistic_cv(df, target_col=\"fire\")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa199df",
   "metadata": {},
   "source": [
    "## Building K-Nearest Neighbors (KNN) From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "class MyKNNClassifier:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        y_pred = []\n",
    "        for x in X:\n",
    "            distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_neighbor_labels = self.y_train[k_indices]\n",
    "            most_common = Counter(k_neighbor_labels).most_common(1)[0][0]\n",
    "            y_pred.append(most_common)\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = MyKNNClassifier(k=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
